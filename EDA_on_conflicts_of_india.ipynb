{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmZZQm3xN-SZ"
      },
      "source": [
        "##**DISPUTE HAPPENED IN INDIA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tY8oBew_OUqg"
      },
      "source": [
        "## 1. Downloading packages and importing dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqCVgakB2q3o",
        "outputId": "2336900d-ffe8-4c65-9720-7ecc25a9fb0a"
      },
      "outputs": [],
      "source": [
        "!pip install pmdarima\n",
        "!pip install tensorflow scikit-learn numpy pandas matplotlib\n",
        "!pip install xgboost\n",
        "!pip install lightgbm\n",
        "!pip install prophet\n",
        "!pip install folium\n",
        "!pip install lifelines\n",
        "!pip install pulp\n",
        "!apt-get install -y glpk\n",
        "!apt-get install -y coinor-cbc\n",
        "!pip install gurobipy\n",
        "!pip install pyomo\n",
        "!pip install pgmpy\n",
        "!pip install stable-baselines3 gym numpy\n",
        "!pip install 'shimmy>=2.0'\n",
        "!pip install stable-baselines3[extra] gymnasium pygame\n",
        "!pip install dowhy\n",
        "!pip install torch torchvision torchaudio pandas scikit-learn\n",
        "!pip install tensorflow\n",
        "!pip install geopandas\n",
        "!pip install branca\n",
        "!pip install sweetviz\n",
        "!pip install pandas-profiling\n",
        "!pip install -U pandas_profiling\n",
        "!pip install ydata_profiling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MZXFYiWPJJ4"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqaEG5IwOhIJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "sns.set()\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3Uhh_jLPwb6"
      },
      "source": [
        "LOADING DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWezr_L5PsAz"
      },
      "outputs": [],
      "source": [
        "conflict = pd.read_csv('https://raw.githubusercontent.com/bhadri-Raj-T/eda_project/refs/heads/main/dispute_dataset.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzeYPEmJR0nN"
      },
      "source": [
        "#1. Data Pre-processing(Data Cleaning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITmcIHhEh79y"
      },
      "source": [
        "Making a copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ev1FQkLh_wm"
      },
      "outputs": [],
      "source": [
        "conflict_copy=conflict.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Tk1BzWzk_0g"
      },
      "source": [
        "Checking missing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFTlDaq3sxZ8",
        "outputId": "728b9995-bd46-4167-d3c4-b74bcf713268"
      },
      "outputs": [],
      "source": [
        "miss=conflict_copy.isnull().sum()\n",
        "miss1 = (conflict_copy.isnull().sum()/len(conflict))* 100\n",
        "m = pd.concat([miss,miss1],axis=1,keys=['Total','Missing%'])\n",
        "m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fFqgogwsxZ8"
      },
      "source": [
        "- From the above output we can see that __director__ , __cast__ ,**country** columns contains __maximum null values__. We will see how to deal with them.\n",
        "\n",
        "- So, We Delete director and cast columns because they are not going to use those features right now."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysoMUhRCl6MM"
      },
      "source": [
        "Visualizing missing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eN1wkyGZl5N7",
        "outputId": "157219cb-7719-479b-fc42-49f79d8be671"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(conflict_copy.isnull(), cbar=False, cmap=\"viridis\")\n",
        "plt.title(\"Missing Data Heatmap\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4jL6KBcgt3H"
      },
      "source": [
        "Handling missing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5Fb70o1mGMS"
      },
      "outputs": [],
      "source": [
        "conflict_copy = conflict_copy.dropna(axis=1, thresh=0.7 * len(conflict_copy))\n",
        "conflict_copy = conflict_copy.dropna(axis=0, subset=['conflict_name', 'type_of_violence'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcBhBbFlsxZ8"
      },
      "outputs": [],
      "source": [
        "conflict_copy['deaths_a'].fillna(conflict_copy['deaths_a'].median(), inplace=True)\n",
        "conflict_copy['deaths_b'].fillna(0, inplace=True)\n",
        "conflict_copy['source_original'].fillna('Unknown', inplace=True)\n",
        "conflict_copy['where_description'].fillna('No Description', inplace=True)\n",
        "conflict_copy['adm_1'].fillna('Unknown', inplace=True)\n",
        "conflict_copy['adm_2'].fillna('Unknown', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFlgAqxAsxZ8",
        "outputId": "1b2d94af-8715-45d0-efd4-d77805256494"
      },
      "outputs": [],
      "source": [
        "conflict_copy.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XosBVD2jbWTv"
      },
      "source": [
        "Converting data types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xSLU5bPchXB"
      },
      "outputs": [],
      "source": [
        "conflict_copy['id'] = conflict_copy['id'].astype(int)\n",
        "conflict_copy['conflict_dset_id'] = conflict_copy['conflict_dset_id'].astype(int)\n",
        "conflict_copy['conflict_new_id'] = conflict_copy['conflict_new_id'].astype(int)\n",
        "conflict_copy['dyad_dset_id'] = conflict_copy['dyad_dset_id'].astype(int)\n",
        "conflict_copy['dyad_new_id'] = conflict_copy['dyad_new_id'].astype(int)\n",
        "conflict_copy['side_a_dset_id'] = conflict_copy['side_a_dset_id'].astype(int)\n",
        "conflict_copy['side_a_new_id'] = conflict_copy['side_a_new_id'].astype(int)\n",
        "conflict_copy['side_b_dset_id'] = conflict_copy['side_b_dset_id'].astype(int)\n",
        "conflict_copy['side_b_new_id'] = conflict_copy['side_b_new_id'].astype(int)\n",
        "conflict_copy['priogrid_gid'] = conflict_copy['priogrid_gid'].astype(int)\n",
        "conflict_copy['country_id'] = conflict_copy['country_id'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqhXEB6ufwg5"
      },
      "outputs": [],
      "source": [
        "conflict_copy['type_of_violence'] = conflict_copy['type_of_violence'].astype('category')\n",
        "conflict_copy['event_clarity'] = conflict_copy['event_clarity'].astype('category')\n",
        "conflict_copy['date_prec'] = conflict_copy['date_prec'].astype('category')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Es2HkSG6f82-"
      },
      "outputs": [],
      "source": [
        "conflict_copy['date_start'] = pd.to_datetime(conflict_copy['date_start'], errors='coerce')\n",
        "conflict_copy['date_end'] = pd.to_datetime(conflict_copy['date_end'], errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pk2CI-dsgIeG"
      },
      "outputs": [],
      "source": [
        "count_columns = ['number_of_sources', 'deaths_a', 'deaths_b', 'deaths_civilians', 'deaths_unknown', 'best', 'high', 'low']\n",
        "conflict_copy[count_columns] = conflict_copy[count_columns].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdP4i5PLgJYi"
      },
      "outputs": [],
      "source": [
        "categorical_cols = ['code_status', 'conflict_name', 'dyad_name', 'side_a', 'side_b', 'country', 'iso3', 'region']\n",
        "conflict_copy[categorical_cols] = conflict_copy[categorical_cols].astype('category')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNO9-pHecp75"
      },
      "outputs": [],
      "source": [
        "conflict_copy['active_year'] = pd.to_numeric(conflict_copy['year'], errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZHWhnXKXbW6"
      },
      "outputs": [],
      "source": [
        "conflict_copy['latitude'] = pd.to_numeric(conflict_copy['latitude'], errors='coerce')\n",
        "conflict_copy['longitude'] = pd.to_numeric(conflict_copy['longitude'], errors='coerce')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcq1rtosqLUT"
      },
      "source": [
        "Log Transformation of Death Counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPaa7QIhpbuE"
      },
      "outputs": [],
      "source": [
        "# Apply log transformation (add 1 to avoid log(0))\n",
        "conflict_copy[['deaths_a', 'deaths_b', 'deaths_civilians', 'deaths_unknown']] = \\\n",
        "    np.log1p(conflict_copy[['deaths_a', 'deaths_b', 'deaths_civilians', 'deaths_unknown']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKxY7o4irD8g"
      },
      "source": [
        "Cleaning and Filtering Conflict Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RQrSr7cP9jE",
        "outputId": "53ab3987-2276-4da2-956a-58e343209dda"
      },
      "outputs": [],
      "source": [
        "# 1Ô∏è‚É£ Drop the first row (it contains headers, not real data)\n",
        "df=conflict.copy()\n",
        "df_clean = df.iloc[1:].copy()\n",
        "\n",
        "# 2Ô∏è‚É£ Convert data types\n",
        "df_clean[\"year\"] = pd.to_numeric(df_clean[\"year\"], errors='coerce')\n",
        "df_clean[\"latitude\"] = pd.to_numeric(df_clean[\"latitude\"], errors='coerce')\n",
        "df_clean[\"longitude\"] = pd.to_numeric(df_clean[\"longitude\"], errors='coerce')\n",
        "df_clean[\"best\"] = pd.to_numeric(df_clean[\"best\"], errors='coerce')\n",
        "df_clean[\"date_start\"] = pd.to_datetime(df_clean[\"date_start\"], errors='coerce')\n",
        "df_clean[\"date_end\"] = pd.to_datetime(df_clean[\"date_end\"], errors='coerce')\n",
        "\n",
        "# 3Ô∏è‚É£ Filter for only India\n",
        "df_clean = df_clean[df_clean[\"country\"] == \"India\"].copy()\n",
        "\n",
        "# 4Ô∏è‚É£ Drop columns with more than 50% missing values\n",
        "missing_threshold = 0.5\n",
        "cols_to_drop = df_clean.columns[df_clean.isnull().mean() > missing_threshold]\n",
        "df_clean.drop(columns=cols_to_drop, inplace=True)\n",
        "\n",
        "# 5Ô∏è‚É£ Drop rows with missing essential fields\n",
        "critical_cols = [\"latitude\", \"longitude\", \"year\", \"best\", \"type_of_violence\", \"date_start\", \"date_end\"]\n",
        "df_clean.dropna(subset=critical_cols, inplace=True)\n",
        "\n",
        "# 6Ô∏è‚É£ Fill non-critical missing fields with placeholders\n",
        "df_clean.fillna({\n",
        "    \"adm_1\": \"Unknown\",\n",
        "    \"adm_2\": \"Unknown\",\n",
        "    \"where_description\": \"Unknown\",\n",
        "    \"side_a\": \"Unknown\",\n",
        "    \"side_b\": \"Unknown\"\n",
        "}, inplace=True)\n",
        "\n",
        "# ‚úÖ Summary after cleaning\n",
        "print(\"\\nCleaned Data Shape:\", df_clean.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Fx8vOP8dTkE"
      },
      "outputs": [],
      "source": [
        "df1=conflict_copy.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gqqFOlQdHpX"
      },
      "outputs": [],
      "source": [
        "df1.rename(columns={'best': 'best_est'}, inplace=True)\n",
        "df1['date_start'] = pd.to_datetime(df1['date_start'], errors='coerce')\n",
        "df1['date_end'] = pd.to_datetime(df1['date_end'], errors='coerce')\n",
        "df1['year'] = df1['year'].astype('str')\n",
        "df1['year'] = df1['year'].astype('int')\n",
        "# Convert important columns to numeric\n",
        "numeric_cols = [\n",
        "    'best_est', 'deaths_a', 'deaths_b',\n",
        "    'deaths_civilians', 'deaths_unknown',\n",
        "    'latitude', 'longitude'\n",
        "]\n",
        "\n",
        "# Convert each column to float\n",
        "for col in numeric_cols:\n",
        "    df1[col] = pd.to_numeric(df1[col], errors='coerce')\n",
        "df1['event_duration'] = (df1['date_end'] - df1['date_start']).dt.days\n",
        "df1['location_precision'] = df1['where_prec'].map({\n",
        "    1: 'Exact', 2: 'Near', 3: 'ADM2', 4: 'ADM1',\n",
        "    5: 'BroadArea', 6: 'CountryOnly', 7: 'Unknown'\n",
        "})\n",
        "# Drop rows with missing target or year\n",
        "df1.dropna(subset=['best_est', 'year'], inplace=True)\n",
        "\n",
        "# Optional: fill or drop missing locations\n",
        "df1['adm_1'].fillna(\"Unknown\", inplace=True)\n",
        "df1['adm_2'].fillna(\"Unknown\", inplace=True)\n",
        "df1['where_description'].fillna(\"Unknown\", inplace=True)\n",
        "\n",
        "# Drop duplicates\n",
        "df1.drop_duplicates(inplace=True)\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Compute z-scores of the target variable\n",
        "df1['zscore_best_est'] = zscore(df1['best_est'])\n",
        "\n",
        "# Remove extreme outliers (z > 3 or z < -3)\n",
        "df1 = df1[(df1['zscore_best_est'] < 3) & (df1['zscore_best_est'] > -3)]\n",
        "\n",
        "# Drop the zscore column\n",
        "df1.drop(columns='zscore_best_est', inplace=True)\n",
        "df1.drop(columns=['geom_wkt', 'relid', 'code_status'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6J59H67RDE-"
      },
      "source": [
        "#2. Data Profiling (Descriptive Analysis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IliZhibO-2is"
      },
      "source": [
        "Visualize missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "JyI7Nmx_vekO",
        "outputId": "e87a5881-f587-424d-a5f9-71c7f356822f"
      },
      "outputs": [],
      "source": [
        "# Visualize missing values\n",
        "sns.heatmap(conflict_copy.isnull(), cbar=False, cmap=\"viridis\")\n",
        "plt.title(\"Missing Data Heatmap\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVAup9xFwM4D"
      },
      "source": [
        "Displaying the First 5 Rows of the DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "e26QRyZ1RKNA",
        "outputId": "690e58dd-7bcb-47cf-9e4f-f195fc557741"
      },
      "outputs": [],
      "source": [
        "conflict_copy.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gd05XtGrwlZU"
      },
      "source": [
        "Displaying the Last 5 Rows of the DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "id": "yh_ZQ7gwROIx",
        "outputId": "bb65fccd-8880-4896-891c-dee78229728b"
      },
      "outputs": [],
      "source": [
        "conflict_copy.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RumtvQS5JrWO"
      },
      "source": [
        "Checking the shape of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dTaBzeUsxZ5",
        "outputId": "0a82fec8-1f77-428e-b757-bdf558354021"
      },
      "outputs": [],
      "source": [
        "conflict_copy.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BgEi0ChJ5r2"
      },
      "source": [
        " Checking the Total Number of Elements in the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ue77YmaesxZ6",
        "outputId": "03318362-e4d9-4bce-da43-389a616361e4"
      },
      "outputs": [],
      "source": [
        "conflict_copy.size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex28X0guKL3a"
      },
      "source": [
        "Listing All Column Names in the Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RegR6W8SsxZ6",
        "outputId": "5e804c85-4237-4700-ffd1-0349ab57687a"
      },
      "outputs": [],
      "source": [
        "conflict_copy.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAAyuHdsKWdP"
      },
      "source": [
        "Checking Data Types of Each Column in the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZwZ4NItnsxZ6",
        "outputId": "d7a0992e-e302-4bb2-d656-ee4b63977e7f"
      },
      "outputs": [],
      "source": [
        "conflict_copy.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbm5dgkFKev6"
      },
      "source": [
        "Displaying Dataset Information Including Non-Null Counts and Data Types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0eE5dYksxZ7",
        "outputId": "1baac969-6c9f-4ea9-8f98-68ae4e71e36b"
      },
      "outputs": [],
      "source": [
        "conflict_copy.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfM5iYDiouUn"
      },
      "source": [
        "Statistics of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "-Bl7OVIgsxZ7",
        "outputId": "f65d8c95-023d-4e6e-84cb-1856e3531cd8"
      },
      "outputs": [],
      "source": [
        "conflict_copy.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdYpMtj4Km4k"
      },
      "source": [
        "Generating Descriptive Statistics for All Columns in the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "Kg9x9KvOsxZ7",
        "outputId": "d361a7b0-4433-4212-d715-2a47ae737ac5"
      },
      "outputs": [],
      "source": [
        "conflict_copy.describe(include='all')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xG85-p39pqxO"
      },
      "source": [
        "Checking the Number of Unique Values in Each Column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W5B2MiVRsxZ7",
        "outputId": "15e4c86a-ca41-40c4-f77d-32a8d2c58dd1"
      },
      "outputs": [],
      "source": [
        "conflict_copy.nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAYMY2lZy2qt"
      },
      "source": [
        "Catagorizing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNS3BZjcy2b3"
      },
      "outputs": [],
      "source": [
        "categorical_cols = [\"code_status\",\"type_of_violence\",\"active_year\", \"where_prec\",\"conflict_name\",\"dyad_name\",\"side_a\",\"side_b\",\"source_article\",\"source_original\",\"where_coordinates\",\"where_description\",\"adm_1\",\"adm_2\",\"geom_wkt\",\"country\",\"iso3\",\"region\",\"event_clarity\",\"date_prec\",]  # Example categorical columns\n",
        "numerical_cols = [\"latitude\", \"longitude\", \"deaths_a\", \"deaths_b\", \"deaths_civilians\", \"deaths_unknown\", \"best\", \"high\", \"low\",\"number_of_sources\",\"priogrid_gid\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uLGs1pgTlyr"
      },
      "source": [
        "**Univariate Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "bZ5uncbdTlbd",
        "outputId": "f97daad0-389e-41a0-96e7-de0800f372e5"
      },
      "outputs": [],
      "source": [
        "# Distribution of 'type_of_violence'\n",
        "sns.countplot(x='type_of_violence', data=conflict_copy)\n",
        "plt.title(\"Distribution of Type of Violence\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urQsbIZeLrz5"
      },
      "source": [
        "Histogram for Deaths (Side A)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "hpDAsvKmsBc4",
        "outputId": "52dca66e-dd8f-4917-8e4a-d8ad7025431e"
      },
      "outputs": [],
      "source": [
        "# Histogram for 'deaths_a'\n",
        "conflict_copy['deaths_a'].hist(bins=50, edgecolor='black')\n",
        "plt.title(\"Distribution of Deaths (Side A)\")\n",
        "plt.xlabel(\"Deaths (Side A)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cl8U_WvJMImH"
      },
      "source": [
        "**Visualizing Conflict Locations on a Map**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        },
        "id": "gTNIY32TWN5U",
        "outputId": "f789493b-d69a-4914-ea50-1ef15071dc42"
      },
      "outputs": [],
      "source": [
        "import folium\n",
        "\n",
        "# Create a map centered at the average location\n",
        "m = folium.Map(location=[conflict_copy['latitude'].mean(), conflict_copy['longitude'].mean()], zoom_start=2)\n",
        "\n",
        "# Add markers for each conflict location\n",
        "for _, row in conflict_copy.iterrows():\n",
        "    folium.CircleMarker(\n",
        "        location=(row['latitude'], row['longitude']),\n",
        "        radius=3,\n",
        "        color='red',\n",
        "        fill=True,\n",
        "        fill_color='red'\n",
        "    ).add_to(m)\n",
        "\n",
        "m\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI6oB5idmG8G"
      },
      "source": [
        "**Checking for Anomalies and Outliers**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "A5VHSVhUmFCh",
        "outputId": "29917d0a-8097-437a-ed7e-82f953a420c8"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "numerical_cols = conflict_copy.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "for col in numerical_cols:\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    sns.boxplot(x=conflict_copy[col])\n",
        "    plt.title(f\"Boxplot for {col}\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0rOKqa2mlqB"
      },
      "source": [
        "**Relationship Between Variables**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9oAvT9lmuQ7"
      },
      "source": [
        "**Scatter Plots**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TvGgqJwamxau",
        "outputId": "8d14c514-d9ae-4704-bf51-675a9a146f2f"
      },
      "outputs": [],
      "source": [
        "# Scatter plot for numerical relationships\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x='deaths_a', y='deaths_civilians', data=conflict_copy, hue='type_of_violence')\n",
        "plt.title(\"Deaths (Side A) vs. Civilian Deaths\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x='latitude', y='longitude', data=conflict_copy, hue='region')\n",
        "plt.title(\"Geographical Spread of Conflicts by Region\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdMCSbdrm7WB"
      },
      "source": [
        "Pairplot for Numerical Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5z-hYHeVm6lY",
        "outputId": "c8300235-12d7-4ea4-9744-517e2be81ad3"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(conflict_copy, vars=['deaths_a', 'deaths_b', 'deaths_civilians', 'deaths_unknown'], hue='type_of_violence')\n",
        "plt.show()\n",
        "sns.pairplot(conflict_copy, vars=numerical_cols, hue='type_of_violence')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUO80ol_nH4u"
      },
      "source": [
        "**Time-Series Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VS4zISHQnMCN"
      },
      "source": [
        "**Conflict Trends Over the Years**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "UaSLSw3gnHk3",
        "outputId": "45a22450-54ea-462e-f4dc-988da821559b"
      },
      "outputs": [],
      "source": [
        "conflicts_by_year = conflict.groupby('year').size()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "conflicts_by_year.plot(kind='line', title='Number of Conflicts Over the Years', marker='o')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Number of Conflicts')\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ollxn-enwQY"
      },
      "source": [
        "**Casualties Over Time**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "0LyEmFMGnlu4",
        "outputId": "2b7bc414-d66f-4430-b539-69fef2b7278e"
      },
      "outputs": [],
      "source": [
        "# Aggregate casualties by year\n",
        "casualties_by_year = conflict.groupby('year')[['deaths_a', 'deaths_b', 'deaths_civilians']].sum()\n",
        "\n",
        "# Plot casualties over time\n",
        "casualties_by_year.plot(kind='line', figsize=(12, 6), title='Casualties Over Time')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Number of Casualties')\n",
        "plt.legend(['Deaths Side A', 'Deaths Side B', 'Civilian Deaths'])\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaP2-x1-2Jdh"
      },
      "source": [
        "skewness and kurtosis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 805
        },
        "id": "h9-YXrdb2JR8",
        "outputId": "84f78a3c-f30f-4681-b26b-b37660a5c569"
      },
      "outputs": [],
      "source": [
        "conflict_copy[numerical_cols].skew()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 805
        },
        "id": "DqQ4Mb5T5gkb",
        "outputId": "2cc2b120-1e45-424d-9548-78f488987fd5"
      },
      "outputs": [],
      "source": [
        "conflict_copy[numerical_cols].kurtosis()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wo_Q_g8RPhuG"
      },
      "source": [
        "Aggregate yearly statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3eWgL5dPhbn"
      },
      "outputs": [],
      "source": [
        "violence_type_map = {1: \"State-based\", 2: \"Non-state\", 3: \"One-sided\"}\n",
        "df_clean[\"violence_type\"] = df_clean[\"type_of_violence\"].map(violence_type_map)\n",
        "\n",
        "yearly_summary = df_clean.groupby([\"year\", \"violence_type\"]).agg(\n",
        "    total_events=(\"id\", \"count\"),\n",
        "    total_fatalities=(\"best\", \"sum\")\n",
        ").reset_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DWWW0FgQaVk"
      },
      "source": [
        "Total Conflict Events per Year in India by Conflict Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "g9yfh4i4PnEs",
        "outputId": "7af2efad-5933-4595-c727-fe3c85b1a13f"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "sns.lineplot(data=yearly_summary, x=\"year\", y=\"total_events\", hue=\"violence_type\", marker=\"o\")\n",
        "plt.title(\"Total Conflict Events per Year in India by Conflict Type\")\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Number of Events\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CPgtcTLQbq4"
      },
      "source": [
        "Total Fatalities Per Year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "jSVo3lGrQbX8",
        "outputId": "f3c11891-f200-4420-8863-7a747f8999d2"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "sns.lineplot(data=yearly_summary, x=\"year\", y=\"total_fatalities\", hue=\"violence_type\", marker=\"o\")\n",
        "plt.title(\"Total Fatalities per Year in India by Conflict Type\")\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Number of Fatalities (Best Estimate)\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyUGIb27Q076"
      },
      "source": [
        "Top 10 conflict-heavy states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "9hTMy1AoQ0wl",
        "outputId": "f47e8e07-6585-44c7-8603-090685ca3a01"
      },
      "outputs": [],
      "source": [
        "state_summary = df_clean.groupby(\"adm_1\").agg(\n",
        "    total_events=(\"id\", \"count\"),\n",
        "    total_fatalities=(\"best\", \"sum\")\n",
        ").sort_values(by=\"total_fatalities\", ascending=False).reset_index()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=state_summary.head(10), x=\"total_fatalities\", y=\"adm_1\", palette=\"Reds_r\")\n",
        "plt.title(\"Top 10 Conflict-Hit States by Fatalities\")\n",
        "plt.xlabel(\"Total Fatalities\")\n",
        "plt.ylabel(\"State (adm_1)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5uj5hzFRBwX"
      },
      "source": [
        "Visual representation of conflicts on map\\\n",
        "Try zooming and check the map!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        },
        "id": "XSq1BerVRBnG",
        "outputId": "0c8d50c7-afdb-476c-a22a-5852897e4aed"
      },
      "outputs": [],
      "source": [
        "import folium\n",
        "from folium.plugins import MarkerCluster\n",
        "\n",
        "# üìç Create a folium map centered on India\n",
        "india_map = folium.Map(location=[22.5937, 78.9629], zoom_start=5, tiles='CartoDB positron')\n",
        "\n",
        "# üìç Cluster markers for conflicts\n",
        "marker_cluster = MarkerCluster().add_to(india_map)\n",
        "\n",
        "# Add markers\n",
        "for idx, row in df_clean.iterrows():\n",
        "    folium.CircleMarker(\n",
        "        location=[row[\"latitude\"], row[\"longitude\"]],\n",
        "        radius=3,\n",
        "        color=\"red\",\n",
        "        fill=True,\n",
        "        fill_opacity=0.6,\n",
        "        popup=folium.Popup(f\"{row['conflict_name']}<br>Fatalities: {row['best']}\", max_width=200)\n",
        "    ).add_to(marker_cluster)\n",
        "\n",
        "# Display the map\n",
        "india_map\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBwPlRnIRQd0"
      },
      "source": [
        "MAP heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        },
        "id": "GliyGSc5RQSq",
        "outputId": "5b88ace9-4388-4392-d029-5f179ab6999a"
      },
      "outputs": [],
      "source": [
        "import folium\n",
        "from folium.plugins import HeatMap\n",
        "import branca.colormap as cm\n",
        "\n",
        "# üåç Create base map\n",
        "heatmap_map = folium.Map(location=[22.9734, 78.6569], zoom_start=5, tiles=\"CartoDB positron\")\n",
        "\n",
        "# üß™ Prepare heatmap data\n",
        "heat_data = [[row[\"latitude\"], row[\"longitude\"], row[\"best\"]] for index, row in df_clean.iterrows() if not np.isnan(row[\"best\"])]\n",
        "\n",
        "# üî• Add heatmap\n",
        "HeatMap(heat_data, radius=10, blur=15, max_zoom=10).add_to(heatmap_map)\n",
        "\n",
        "# üé® Add custom color legend\n",
        "colormap = cm.LinearColormap(\n",
        "    colors=[\"green\", \"yellow\", \"orange\", \"red\"],\n",
        "    vmin=df_clean[\"best\"].min(),\n",
        "    vmax=df_clean[\"best\"].max(),\n",
        "    caption=\"Conflict Fatalities (Best Estimate)\"\n",
        ")\n",
        "colormap.add_to(heatmap_map)\n",
        "\n",
        "# Show the map\n",
        "heatmap_map\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmriFXJSRVn7"
      },
      "source": [
        "Top Conflict States Colored by Fatality Range"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "-zQJyD8dRVZK",
        "outputId": "c5c1b86f-d9fb-4b17-caae-43eade522583"
      },
      "outputs": [],
      "source": [
        "bins = [0, 10, 100, 500, 1000, df_clean[\"best\"].max()]\n",
        "labels = [\"0-10\", \"11-100\", \"101-500\", \"501-1000\", \"1000+\"]\n",
        "df_clean[\"fatality_range\"] = pd.cut(df_clean[\"best\"], bins=bins, labels=labels)\n",
        "\n",
        "# Barplot with color by range\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.countplot(data=df_clean, y=\"adm_1\", hue=\"fatality_range\", order=df_clean[\"adm_1\"].value_counts().index[:10])\n",
        "plt.title(\"Top Conflict States Colored by Fatality Range\")\n",
        "plt.xlabel(\"Number of Events\")\n",
        "plt.ylabel(\"State\")\n",
        "plt.legend(title=\"Fatality Range\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "al9oQuaFRi0p"
      },
      "source": [
        "Top 10 most affected districts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "Fmie3r11Rioz",
        "outputId": "abfc2265-8e68-43c9-ba79-d817d1ef52f2"
      },
      "outputs": [],
      "source": [
        "district_summary = df_clean.groupby(\"adm_2\").agg(\n",
        "    total_events=(\"id\", \"count\"),\n",
        "    total_fatalities=(\"best\", \"sum\")\n",
        ").sort_values(by=\"total_fatalities\", ascending=False).reset_index()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=district_summary.head(10), x=\"total_fatalities\", y=\"adm_2\", palette=\"Oranges_r\")\n",
        "plt.title(\"Top 10 Conflict-Hit Districts by Fatalities\")\n",
        "plt.xlabel(\"Total Fatalities\")\n",
        "plt.ylabel(\"District (adm_2)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FYy5xtRRrwp"
      },
      "source": [
        "Plot Top 10 dyads by fatalities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "8L8UWipJRrlN",
        "outputId": "5e68ef2c-b81e-493c-d860-bd35456187d2"
      },
      "outputs": [],
      "source": [
        "# üéØ Top Actors (side A and B) by number of events\n",
        "top_side_a = df_clean[\"side_a\"].value_counts().head(10)\n",
        "top_side_b = df_clean[\"side_b\"].value_counts().head(10)\n",
        "\n",
        "# üî• Fatalities by Dyad (interaction)\n",
        "dyad_fatalities = df_clean.groupby(\"dyad_name\").agg(\n",
        "    total_events=(\"id\", \"count\"),\n",
        "    total_fatalities=(\"best\", \"sum\")\n",
        ").sort_values(by=\"total_fatalities\", ascending=False).reset_index()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=dyad_fatalities.head(10), x=\"total_fatalities\", y=\"dyad_name\", palette=\"Blues_r\")\n",
        "plt.title(\"Top 10 Actor Dyads by Conflict Fatalities\")\n",
        "plt.xlabel(\"Total Fatalities\")\n",
        "plt.ylabel(\"Actor Dyad\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwW4WtnvRyUo"
      },
      "source": [
        "Top side_a actors (e.g., Government of India, Army, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "blunakSIRyIb",
        "outputId": "68330abb-e31b-45fa-cc96-1d0926152a7a"
      },
      "outputs": [],
      "source": [
        "\n",
        "side_a_stats = df_clean.groupby(\"side_a\").agg(\n",
        "    total_events=(\"id\", \"count\"),\n",
        "    total_fatalities=(\"best\", \"sum\"),\n",
        "    civilian_deaths=(\"deaths_civilians\", \"sum\")\n",
        ").sort_values(by=\"total_fatalities\", ascending=False).reset_index()\n",
        "\n",
        "# Top 10\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=side_a_stats.head(10), x=\"total_fatalities\", y=\"side_a\", palette=\"Reds_r\")\n",
        "plt.title(\"Top State Forces (Side A) by Total Fatalities\")\n",
        "plt.xlabel(\"Total Fatalities\")\n",
        "plt.ylabel(\"Side A (State Forces)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZ7AFO-yR5M7"
      },
      "source": [
        "Top side_b actors (e.g., Maoists, ULFA, LeT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "f0oepBFuR5Ap",
        "outputId": "a8f3290b-f092-4962-90cf-0617505930b0"
      },
      "outputs": [],
      "source": [
        "\n",
        "side_b_stats = df_clean.groupby(\"side_b\").agg(\n",
        "    total_events=(\"id\", \"count\"),\n",
        "    total_fatalities=(\"best\", \"sum\"),\n",
        "    civilian_deaths=(\"deaths_civilians\", \"sum\")\n",
        ").sort_values(by=\"total_fatalities\", ascending=False).reset_index()\n",
        "\n",
        "# Top 10\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=side_b_stats.head(10), x=\"total_fatalities\", y=\"side_b\", palette=\"magma\")\n",
        "plt.title(\"Top Insurgent Groups (Side B) by Total Fatalities\")\n",
        "plt.xlabel(\"Total Fatalities\")\n",
        "plt.ylabel(\"Side B (Non-State Groups)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8jYtSMVvShq"
      },
      "source": [
        "Civilian harm by side_a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "sZK2_mE4vS6U",
        "outputId": "4a1fbab2-31ef-4876-e61b-8ff361c769fc"
      },
      "outputs": [],
      "source": [
        "side_a_civilians = side_a_stats.sort_values(by=\"civilian_deaths\", ascending=False).head(20)\n",
        "side_a_civilians[[\"side_a\", \"total_events\", \"civilian_deaths\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8twT6JatR8Nv"
      },
      "source": [
        "Civilian harm by side_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "r535d7asR740",
        "outputId": "b93da260-0627-4725-8e53-adfe677b50b7"
      },
      "outputs": [],
      "source": [
        "side_b_civilians = side_b_stats.sort_values(by=\"civilian_deaths\", ascending=False).head(20)\n",
        "side_b_civilians[[\"side_b\", \"total_events\", \"civilian_deaths\"]]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p42qFTsQlabN"
      },
      "source": [
        "#3. Diagnosis analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFQSFjoLmSSH"
      },
      "source": [
        "**Z-Score Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BFbcFL_-mWT0",
        "outputId": "af8f06b0-7a2d-44b3-9c11-98c02b740fe6"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import zscore\n",
        "\n",
        "z_scores = conflict_copy[numerical_cols].apply(zscore)\n",
        "\n",
        "outliers = conflict_copy[(z_scores.abs() > 3).any(axis=1)]\n",
        "print(\"\\nPotential Outliers:\")\n",
        "outliers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umg0QmfpWDvR"
      },
      "source": [
        "**Correlation Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        },
        "id": "XD2_yQXzVOEJ",
        "outputId": "71c850a1-c39a-4041-bdef-d9b9e832cae8"
      },
      "outputs": [],
      "source": [
        "# Increase figure size\n",
        "plt.figure(figsize=(12, 8))  # Adjust width and height as needed\n",
        "\n",
        "# Correlation heatmap\n",
        "corr = conflict_copy[numerical_cols].corr()\n",
        "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm',linewidths=0.5)\n",
        "\n",
        "plt.title(\"Correlation Heatmap\", fontsize=14)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ligoFCeZ6D11"
      },
      "source": [
        "duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HP-KuxUK6DjT",
        "outputId": "d2b9ba46-a41f-4a9c-c513-b3fc212b7c5f"
      },
      "outputs": [],
      "source": [
        "conflict_copy.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuLLYbis6odM"
      },
      "source": [
        "Find the frequency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yEOQv5j6oSY",
        "outputId": "f64c31ac-bc71-48bf-80a7-4d4ba76d210b"
      },
      "outputs": [],
      "source": [
        "for i in categorical_cols:\n",
        "  print(conflict_copy[i].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfsKtZeM7SIK"
      },
      "source": [
        "Histograms for deaths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a3yjMmEJ7R8Y",
        "outputId": "97ad5d12-e255-4435-bb8d-9203836aad06"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 3, figsize=(18, 15))\n",
        "sns.histplot(conflict_copy[\"deaths_a\"], bins=5, kde=True, ax=axes[0, 0])\n",
        "axes[0, 0].set_title(\"Distribution of Deaths on Side A\")\n",
        "\n",
        "sns.histplot(conflict_copy[\"deaths_b\"], bins=5, kde=True, ax=axes[0, 1])\n",
        "axes[0, 1].set_title(\"Distribution of Deaths on Side B\")\n",
        "\n",
        "sns.histplot(conflict_copy[\"best\"], bins=5, kde=True, ax=axes[0, 2])\n",
        "axes[0, 2].set_title(\"Distribution of Best Estimate of Deaths\")\n",
        "\n",
        "sns.boxplot(y=conflict_copy[\"latitude\"], ax=axes[1, 0])\n",
        "axes[1, 0].set_title(\"Boxplot of Latitude\")\n",
        "\n",
        "sns.boxplot(y=conflict_copy[\"longitude\"], ax=axes[1, 1])\n",
        "axes[1, 1].set_title(\"Boxplot of Longitude\")\n",
        "\n",
        "sns.boxplot(y=conflict_copy[\"best\"], ax=axes[1, 2])\n",
        "axes[1, 2].set_title(\"Boxplot of Best Estimate of Deaths\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnhlRfcbbNh-"
      },
      "source": [
        "MEANS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKmEEXZ-bNZU",
        "outputId": "8def57c3-72c9-4339-907b-3ae25de9647f"
      },
      "outputs": [],
      "source": [
        "# Mean fatalities by violence type\n",
        "print(df_clean.groupby(\"type_of_violence\")[\"best\"].mean())\n",
        "print()\n",
        "# Mean fatalities by region\n",
        "print(df_clean.groupby(\"region\")[\"best\"].mean())\n",
        "print()\n",
        "# Most lethal side_b (insurgent) groups\n",
        "print(df_clean.groupby(\"side_b\")[\"best\"].sum().sort_values(ascending=False).head(10))\n",
        "print()\n",
        "# Most lethal side_a (insurgent) groups\n",
        "print(df_clean.groupby(\"side_a\")[\"best\"].sum().sort_values(ascending=False).head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9KQ51n-dKh-"
      },
      "source": [
        "Impact Assesment and Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "wqBr5U0xdKXY",
        "outputId": "c03a1c02-5476-47cf-ab15-87ab4716af65"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Total deaths by category\n",
        "death_totals = {\n",
        "    \"Civilians\": df[\"deaths_civilians\"].sum(),\n",
        "    \"Side A (Govt forces)\": df[\"deaths_a\"].sum(),\n",
        "    \"Side B (Insurgents)\": df[\"deaths_b\"].sum()\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(death_totals.keys(), death_totals.values(), color=[\"skyblue\", \"orange\", \"tomato\"])\n",
        "plt.title(\"Total Deaths by Conflict Participant Type\")\n",
        "plt.ylabel(\"Number of Fatalities\")\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q76Npfwtxry1"
      },
      "source": [
        "Year-wise Civilian Fatalities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "LZAiDfy4db0o",
        "outputId": "260548e7-71aa-4543-df65-3edf2559e928"
      },
      "outputs": [],
      "source": [
        "df=df1\n",
        "df['year'] = df['date_start'].dt.year\n",
        "\n",
        "civilian_impact = df.groupby(\"year\")[\"deaths_civilians\"].sum()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(civilian_impact.index, civilian_impact.values, marker='o', color='crimson')\n",
        "plt.title(\"Year-wise Civilian Fatalities\")\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Number of Civilian Deaths\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3hbuOledvi7",
        "outputId": "387008a2-9eb3-45a4-ec46-9d0ec180e676"
      },
      "outputs": [],
      "source": [
        "df=df1\n",
        "type_impact = df.groupby(\"type_of_violence\")[[\"best_est\", \"deaths_civilians\"]].mean().rename({\n",
        "    \"best\": \"Avg Total Fatalities\",\n",
        "    \"deaths_civilians\": \"Avg Civilian Fatalities\"\n",
        "}, axis=1)\n",
        "\n",
        "print(type_impact)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7by-66tjyEPK"
      },
      "source": [
        "Civilian Fatalities Over Time by Type of Violence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "F0SZ_mCydxP0",
        "outputId": "59ad9d71-69f6-4f9f-da43-add18bbaeb07"
      },
      "outputs": [],
      "source": [
        "# Group and pivot the data\n",
        "df['year'] = df['date_start'].dt.year\n",
        "\n",
        "civilian_by_type = df.groupby([\"year\", \"type_of_violence\"])[\"deaths_civilians\"].sum().unstack(fill_value=0)\n",
        "\n",
        "# Optional: Rename types for clarity\n",
        "violence_labels = {\n",
        "    1: \"State-based\",\n",
        "    2: \"Non-state\",\n",
        "    3: \"One-sided\"\n",
        "}\n",
        "civilian_by_type.rename(columns=violence_labels, inplace=True)\n",
        "\n",
        "# Plot (stacked area or line)\n",
        "civilian_by_type.plot(kind='area', stacked=True, figsize=(12, 6), colormap='tab10')\n",
        "plt.title(\"Civilian Fatalities Over Time by Type of Violence\")\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Civilian Deaths\")\n",
        "plt.grid(True)\n",
        "plt.legend(title=\"Type of Violence\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXt5cW_MyP-c"
      },
      "source": [
        "Proportion of Side A Fatalities Caused by Side B Groups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        },
        "id": "Ur5lRG90d0g6",
        "outputId": "0758cfb8-3880-41e2-d8eb-70f4ad8ac3b7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Group by side_b and sum side_a deaths\n",
        "side_b_impact = df.groupby(\"side_b\")[\"deaths_a\"].sum().sort_values(ascending=False)\n",
        "\n",
        "# Filter out 0-death entries\n",
        "side_b_impact = side_b_impact[side_b_impact > 0]\n",
        "\n",
        "# Take top N groups, rest as 'Others'\n",
        "top_n = 6\n",
        "top_groups = side_b_impact[:top_n]\n",
        "other = side_b_impact[top_n:].sum()\n",
        "\n",
        "# ‚úÖ Combine using concat instead of append\n",
        "side_b_final = pd.concat([top_groups, pd.Series({\"Others\": other})])\n",
        "\n",
        "# Pie chart\n",
        "plt.figure(figsize=(8, 8))\n",
        "side_b_final.plot(kind='pie', autopct='%1.1f%%', startangle=140, colormap='tab10', textprops={'fontsize': 10})\n",
        "plt.title(\"Proportion of Side A Fatalities Caused by Side B Groups\")\n",
        "plt.ylabel(\"\")  # Hide y-axis label\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R84wBW0yd3xp"
      },
      "source": [
        "Clustering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "sRx3F7Eid3cA",
        "outputId": "33f75b4a-f2a9-45d9-810c-e7fca328589b"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "features = [\"deaths_a\", \"deaths_b\", \"deaths_civilians\"]\n",
        "df_cluster = df[features].fillna(0)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(df_cluster)\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "wcss = []\n",
        "for i in range(1, 10):\n",
        "    kmeans = KMeans(n_clusters=i, random_state=42)\n",
        "    kmeans.fit(X_scaled)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(range(1, 10), wcss, marker='o')\n",
        "plt.title(\"Elbow Method - Optimal Clusters\")\n",
        "plt.xlabel(\"Number of Clusters\")\n",
        "plt.ylabel(\"WCSS\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oD85z6uTNiYo"
      },
      "source": [
        " Performing K-Means Clustering to Identify Patterns in the Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76CGgZwed8FT",
        "outputId": "8e18da57-5bbc-4fd4-ca33-00e61962066a"
      },
      "outputs": [],
      "source": [
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "df['cluster'] = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "# See cluster breakdown\n",
        "print(df['cluster'].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JUh-q6GNs4H"
      },
      "source": [
        "Visualizing Clusters Using PCA (Principal Component Analysis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "3L3Q4-8UeCkY",
        "outputId": "5f161dd4-e85e-4172-8160-a374eb4d8075"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reduce to 2 principal components for 2D visualization\n",
        "pca = PCA(n_components=2)\n",
        "pca_result = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Add to DataFrame for plotting\n",
        "df['pca1'] = pca_result[:, 0]\n",
        "df['pca2'] = pca_result[:, 1]\n",
        "\n",
        "# Plot clusters\n",
        "plt.figure(figsize=(10, 6))\n",
        "scatter = plt.scatter(df['pca1'], df['pca2'], c=df['cluster'], cmap='tab10', alpha=0.6)\n",
        "plt.title(\"Clustering of Conflict Events Based on Fatalities\")\n",
        "plt.xlabel(\"PCA 1\")\n",
        "plt.ylabel(\"PCA 2\")\n",
        "plt.legend(*scatter.legend_elements(), title=\"Cluster\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-yMZixRN1Le"
      },
      "source": [
        "Analyzing Cluster Profiles by Calculating the Mean of Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDBCLjMyeFXr",
        "outputId": "4e372468-e8d5-4785-fa5b-f7585191e95e"
      },
      "outputs": [],
      "source": [
        "# Group by cluster and calculate mean of features\n",
        "cluster_summary = df.groupby(\"cluster\")[[\"deaths_a\", \"deaths_b\", \"deaths_civilians\"]].mean()\n",
        "print(\" Cluster Profiles:\")\n",
        "print(cluster_summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ube3y6PeIxr"
      },
      "source": [
        "A cluster with high deaths_b ‚Üí intense insurgent targeting\n",
        "\n",
        "High deaths_a ‚Üí state retaliation/failure\n",
        "\n",
        "High deaths_civilians ‚Üí violent civilian-targeted events"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e05dKkc7eMvm"
      },
      "source": [
        "Cluster 0:  Low-intensity conflicts(Small-scale, frequent events with minor casualties)\n",
        "\n",
        "Cluster 1:  Government-targeted massacre\n",
        "\n",
        "Cluster 2: Major armed conflicts(Extremely high insurgent fatalities, some state losses, no civilian impact ‚Äî likely major military ops)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "id": "HP7GBaGleMi4",
        "outputId": "a39c9b2c-286a-4bdd-ce04-76809f09d086"
      },
      "outputs": [],
      "source": [
        "conflict_type_map = {1: \"State-based\", 2: \"Non-state\", 3: \"One-sided\"}\n",
        "df[\"violence_type_name\"] = df[\"type_of_violence\"].map(conflict_type_map)\n",
        "\n",
        "# Count per cluster & violence type\n",
        "ct_counts = df.groupby([\"cluster\", \"violence_type_name\"]).size().unstack(fill_value=0)\n",
        "print(ct_counts)\n",
        "\n",
        "# Plot\n",
        "ct_counts.plot(kind='bar', stacked=True, figsize=(10, 5), colormap='Set3')\n",
        "plt.title(\"Distribution of Conflict Types per Cluster\")\n",
        "plt.ylabel(\"Number of Events\")\n",
        "plt.xlabel(\"Cluster\")\n",
        "plt.legend(title=\"Type of Violence\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6Z_onnNOEga"
      },
      "source": [
        "### Identifying Top States in Each Cluster Based on Conflict Distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-2TMtsKeII5",
        "outputId": "33b7100a-e7e0-4a20-d431-3232b02e7c04"
      },
      "outputs": [],
      "source": [
        "# Top states in each cluster\n",
        "location_distribution = df.groupby([\"cluster\", \"adm_1\"]).size().unstack(fill_value=0)\n",
        "\n",
        "# Show top 5 locations in each cluster\n",
        "print(\"Top States in Each Cluster:\")\n",
        "for cluster_id in location_distribution.index:\n",
        "    top_states = location_distribution.loc[cluster_id].sort_values(ascending=False).head(5)\n",
        "    print(f\"\\nCluster {cluster_id}:\")\n",
        "    print(top_states)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8H0-cT4UOO8a"
      },
      "source": [
        "### Analyzing Year-wise Distribution of Conflict Clusters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "FEXg2kdNesei",
        "outputId": "0763a1a5-f836-4dc4-a845-7f89caf2b2e6"
      },
      "outputs": [],
      "source": [
        "import geopandas as gpd\n",
        "# Assuming you have year-wise data tagged with cluster labels\n",
        "df.groupby(['year', 'cluster']).size().unstack().plot()\n",
        "plt.title(\"Year-wise Distribution of Conflict Clusters\")\n",
        "plt.ylabel(\"Number of Events\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvkV4mkvmkiM"
      },
      "source": [
        "Clustering using Hierarchical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iu8v4ZNHmkiN",
        "outputId": "47b690d5-5b55-4a08-bfda-421a8833dc42"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import folium\n",
        "\n",
        "df=conflict_copy\n",
        "# Assuming your preprocessed features are in a matrix `X` (e.g., after scaling/encoding)\n",
        "# Example: Select numerical features (adjust as needed)\n",
        "num_features = ['deaths_a', 'deaths_b', 'deaths_civilians', 'best', 'latitude', 'longitude']\n",
        "X = df[num_features]\n",
        "\n",
        "# Standardize features (critical for hierarchical clustering)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Perform hierarchical clustering\n",
        "Z = linkage(X_scaled, method='ward')  # 'ward' minimizes variance; alternatives: 'complete', 'average'\n",
        "\n",
        "# Plot the dendrogram to decide number of clusters\n",
        "plt.figure(figsize=(12, 6))\n",
        "dendrogram(Z, truncate_mode='lastp', p=20, show_leaf_counts=True)\n",
        "plt.title('Dendrogram (Hierarchical Clustering)')\n",
        "plt.xlabel('Sample Index or (Cluster Size)')\n",
        "plt.ylabel('Distance (Ward)')\n",
        "plt.axhline(y=15, color='r', linestyle='--')  # Adjust line to find clusters (e.g., where vertical lines intersect)\n",
        "plt.show()\n",
        "\n",
        "# Choose a distance threshold or number of clusters\n",
        "distance_threshold = 15  # Adjust based on dendrogram\n",
        "n_clusters = 4  # Or use threshold\n",
        "\n",
        "# Assign clusters to data points\n",
        "clusters = fcluster(Z, t=distance_threshold, criterion='distance')  # or `t=n_clusters, criterion='maxclust'`\n",
        "df['cluster'] = clusters\n",
        "\n",
        "# Analyze cluster characteristics\n",
        "cluster_summary = df.groupby('cluster')[num_features].mean()\n",
        "cluster_summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voUrv2qJmkiN",
        "outputId": "cf904135-8eb3-4c46-ed92-04403b23f3b5"
      },
      "outputs": [],
      "source": [
        "# Define merge rules (example: group clusters with similar death profiles)\n",
        "merge_rules = {\n",
        "    # Low-intensity state conflicts (low deaths_a, near-zero deaths_b)\n",
        "    1: 1, 2: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 17: 1, 18: 1,\n",
        "\n",
        "    # High-intensity symmetric (balanced deaths_a and deaths_b)\n",
        "    3: 2, 4: 2, 23: 2, 39: 2, 40: 2, 41: 2, 48: 2, 51: 2, 52: 2,\n",
        "\n",
        "    # Civilian-targeting (high deaths_civilians)\n",
        "    26: 3, 27: 3, 28: 3, 30: 3, 31: 3, 42: 3, 43: 3,\n",
        "\n",
        "    # Extreme events (outliers with massive fatalities)\n",
        "    24: 4, 25: 4, 36: 4, 37: 4, 50: 4,\n",
        "\n",
        "    # Others (default to a new cluster)\n",
        "    **{k: 5 for k in\n",
        "    range(16, 52) if k not in [16, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52]}\n",
        "}\n",
        "\n",
        "df['cluster'] = df['cluster'].replace(merge_rules)\n",
        "cluster_names = {\n",
        "    1: 'Low-Intensity State Conflicts',\n",
        "    2: 'High-Intensity Symmetric Wars',\n",
        "    3: 'Civilian-Targeting Atrocities',\n",
        "    4: 'Mass-Fatality Extreme Events',\n",
        "    5: 'Other Asymmetric Conflicts'\n",
        "}\n",
        "df['cluster_name'] = df['cluster'].map(cluster_names)\n",
        "unmapped_clusters = set(df['cluster'].unique()) - set(merge_rules.keys())\n",
        "print(f\"Unmapped clusters: {unmapped_clusters}\")\n",
        "# Get all original cluster IDs (1-52)\n",
        "all_clusters = set(range(1, 53))\n",
        "\n",
        "# Assign unmapped clusters to \"Other Asymmetric Conflicts\" (cluster 5)\n",
        "merge_rules_complete = {**merge_rules, **{k: 5 for k in all_clusters if k not in merge_rules}}\n",
        "df['cluster'] = df['cluster'].replace(merge_rules_complete)\n",
        "df['cluster_name'] = df['cluster'].map(cluster_names)\n",
        "\n",
        "# Verify no NaN values remain\n",
        "assert df['cluster_name'].isna().sum() == 0, \"Still missing some cluster mappings!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "34t9o86jmkiO",
        "outputId": "86813599-99ef-4d5a-e6ff-a40f1de1b3c8"
      },
      "outputs": [],
      "source": [
        "cluster_summary = df.groupby('cluster_name')[num_features].mean()\n",
        "cluster_summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        },
        "id": "buUKexMxmkiP",
        "outputId": "3a8d7ab1-50f4-4d53-e2e1-ae6473dc7504"
      },
      "outputs": [],
      "source": [
        "# Color mapping for new clusters\n",
        "color_map = {\n",
        "    'Low-Intensity State Conflicts': 'green',\n",
        "    'High-Intensity Symmetric Wars': 'blue',\n",
        "    'Civilian-Targeting Atrocities': 'red',\n",
        "    'Mass-Fatality Extreme Events': 'black',\n",
        "    'Other Asymmetric Conflicts': 'orange'\n",
        "}\n",
        "\n",
        "# Create Folium map\n",
        "map = folium.Map(location=[df['latitude'].mean(), df['longitude'].mean()], zoom_start=5)\n",
        "for _, row in df.iterrows():\n",
        "    folium.CircleMarker(\n",
        "        location=[row['latitude'], row['longitude']],\n",
        "        radius=np.log(row['best'] + 1) * 2,  # Scale by deaths\n",
        "        color=color_map[row['cluster_name']],\n",
        "        fill=True,\n",
        "        tooltip=f\"{row['cluster_name']}: Best={row['best']:.0f}\"\n",
        "    ).add_to(map)\n",
        "map.save('simplified_clusters.html')\n",
        "map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        },
        "id": "r08krIGbmkiP",
        "outputId": "5045319d-268f-4153-e73f-44c471d3c298"
      },
      "outputs": [],
      "source": [
        "map = folium.Map(location=[df['latitude'].mean(), df['longitude'].mean()], zoom_start=5)\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    # Custom popup HTML with cluster details\n",
        "    popup_html = f\"\"\"\n",
        "    <b>Cluster {row['cluster']}</b><br>\n",
        "    <b>Type:</b> {row['cluster_name']}<br>\n",
        "    <b>Deaths (Best):</b> {row['best']:.0f}<br>\n",
        "    <b>Side A Deaths:</b> {row['deaths_a']:.1f}<br>\n",
        "    <b>Side B Deaths:</b> {row['deaths_b']:.1f}<br>\n",
        "    <b>Civilians:</b> {row['deaths_civilians']:.1f}\n",
        "    \"\"\"\n",
        "\n",
        "    folium.CircleMarker(\n",
        "        location=[row['latitude'], row['longitude']],\n",
        "        radius=np.log(row['best'] + 1) * 2,\n",
        "        color=color_map[row['cluster_name']],\n",
        "        fill=True,\n",
        "        popup=folium.Popup(popup_html, max_width=250),  # Popup shows on click\n",
        "        tooltip=f\"Cluster {row['cluster']}\"  # Tooltip on hover\n",
        "    ).add_to(map)\n",
        "\n",
        "map.save(\"map_with_interactive_labels.html\")\n",
        "map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksp9LCgbHi56"
      },
      "source": [
        "DBSCAN (Density-Based Spatial Clustering of Applications with Noise)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lfqQkixXHivu",
        "outputId": "cff24c79-5369-41f8-e090-91d927cfd771"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "df = conflict_copy  # Replace with your dataset\n",
        "\n",
        "# Selecting relevant features for clustering\n",
        "X = df[['latitude', 'longitude']]\n",
        "\n",
        "# Standardize data for better clustering\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Apply DBSCAN clustering\n",
        "dbscan = DBSCAN(eps=0.3, min_samples=5)  # Adjust eps and min_samples based on data density\n",
        "df['cluster'] = dbscan.fit_predict(X_scaled)\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.scatter(df['latitude'], df['longitude'], c=df['cluster'], cmap='viridis', alpha=0.6)\n",
        "plt.xlabel('Latitude')\n",
        "plt.ylabel('Longitude')\n",
        "plt.title('DBSCAN - High-Density Conflict Areas')\n",
        "plt.show()\n",
        "\n",
        "# Remove noise points (cluster = -1)\n",
        "df_filtered = df[df['cluster'] != -1]\n",
        "\n",
        "# Plot results after noise removal\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.scatter(df_filtered['latitude'], df_filtered['longitude'], c=df_filtered['cluster'], cmap='viridis', alpha=0.6)\n",
        "plt.xlabel('Latitude')\n",
        "plt.ylabel('Longitude')\n",
        "plt.title('DBSCAN - High-Density Conflict Areas (Noise Removed)')\n",
        "plt.show()\n",
        "\n",
        "# Count clusters and removed noise points\n",
        "num_clusters = len(set(df_filtered['cluster']))\n",
        "num_noise_points = len(df) - len(df_filtered)\n",
        "\n",
        "print(f\"Number of Clusters: {num_clusters}\")\n",
        "print(f\"Number of Noise Points Removed: {num_noise_points}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xuGT3n1IY6p"
      },
      "source": [
        "Kaplan-Meier Estimator (for time-to-event analysis)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "r-mubaTGIYvT",
        "outputId": "3e60c430-e325-4c08-c9b8-db7765074dd1"
      },
      "outputs": [],
      "source": [
        "from lifelines import KaplanMeierFitter\n",
        "\n",
        "# Load your dataset (Ensure it has a 'duration' column in days/months/years)\n",
        "df = conflict_copy  # Replace with actual dataset\n",
        "\n",
        "# Calculate conflict duration (days)\n",
        "df['duration'] = (df['date_end'] - df['date_start']).dt.days\n",
        "\n",
        "# Censorship column: 1 if conflict ended, 0 if still ongoing\n",
        "df['event_observed'] = df['date_end'].notna().astype(int)\n",
        "\n",
        "# Kaplan-Meier model\n",
        "kmf = KaplanMeierFitter()\n",
        "\n",
        "# Fit the model\n",
        "kmf.fit(df['duration'], event_observed=df['event_observed'])\n",
        "\n",
        "# Plot the survival function\n",
        "plt.figure(figsize=(8, 5))\n",
        "kmf.plot()\n",
        "plt.xlabel(\"Days since Conflict Start\")\n",
        "plt.ylabel(\"Survival Probability\")\n",
        "plt.title(\"Kaplan-Meier Survival Curve for Conflicts\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vG5zKHjSKA-c"
      },
      "source": [
        "Cox Proportional Hazards Model (for multivariate analysis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-Fx_gLSfKAs3",
        "outputId": "20d9468a-5c17-480e-8924-cf8ece22c293"
      },
      "outputs": [],
      "source": [
        "from lifelines import CoxPHFitter\n",
        "\n",
        "# Load dataset (Make sure it has 'start_date', 'end_date', and relevant features)\n",
        "df = conflict_copy\n",
        "\n",
        "# Select features for multivariate analysis\n",
        "features = ['type_of_violence', 'deaths_a', 'deaths_b', 'event_clarity', 'number_of_sources']\n",
        "\n",
        "# Drop rows with missing values\n",
        "df = df.dropna(subset=['duration', 'event_observed'] + features)\n",
        "\n",
        "# Prepare dataset for Cox model\n",
        "cox_data = df[['duration', 'event_observed'] + features]\n",
        "\n",
        "# Fit Cox Proportional Hazards model\n",
        "cph = CoxPHFitter()\n",
        "cph.fit(cox_data, duration_col='duration', event_col='event_observed')\n",
        "\n",
        "# Summary of the model\n",
        "cph.print_summary()\n",
        "\n",
        "# Plot hazard ratios\n",
        "cph.plot()\n",
        "plt.title(\"Cox Proportional Hazards - Hazard Ratios\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5FtWNV1ojQG"
      },
      "source": [
        "Feature Importance with Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "id": "cX07gafsohJ7",
        "outputId": "ff9fd791-d261-4dec-e42a-91d7f05a47dc"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Prepare dataset\n",
        "X = conflict_copy.select_dtypes(include=['float64', 'int64']).drop('best', axis=1, errors='ignore')\n",
        "y = conflict_copy['best']  # Replace 'best' with any target column\n",
        "\n",
        "# Train a Random Forest Classifier\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X.fillna(0), y.fillna(0))  # Replace missing values for simplicity\n",
        "\n",
        "# Feature importance\n",
        "feature_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
        "feature_importances.sort_values().plot(kind='barh', figsize=(10, 6), title=\"Feature Importance\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yObhdh7apyyX"
      },
      "source": [
        "#4. Predictive analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8eqmZEOflewN"
      },
      "outputs": [],
      "source": [
        "model_scores={}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruL9DpG9fPfM"
      },
      "source": [
        "Linear regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "id": "rYYZobQ5fOYp",
        "outputId": "feac8e4f-b2c0-4b9b-ccba-005eab5503c9"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model_scores1 = {}  # Dictionary to store model performance\n",
        "\n",
        "# Features and Target\n",
        "features = ['deaths_a', 'deaths_b', 'deaths_civilians', 'deaths_unknown']\n",
        "target = 'best_est'\n",
        "\n",
        "X = df1[features].fillna(0)\n",
        "y = df1[target].fillna(0)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "\n",
        "# Metrics\n",
        "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
        "rmse_lr = np.sqrt(mse_lr)\n",
        "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
        "r2_lr = r2_score(y_test, y_pred_lr)\n",
        "mape_lr = np.mean(np.abs((y_test - y_pred_lr) / y_test.replace(0, np.nan))) * 100  # Avoid division by zero\n",
        "\n",
        "# Store in dictionary\n",
        "model_scores['Linear Regression'] = {\n",
        "    \"MSE\": mse_lr,\n",
        "    \"RMSE\": rmse_lr,\n",
        "    \"MAE\": mae_lr,\n",
        "    \"R2 Score\": r2_lr,\n",
        "    \"MAPE\": mape_lr\n",
        "}\n",
        "\n",
        "print(\"Linear Regression Metrics:\")\n",
        "for k, v in model_scores['Linear Regression'].items():\n",
        "    print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(y_test.values, label=\"Actual\", color=\"blue\", marker='o')\n",
        "plt.plot(y_pred_lr, label=\"Predicted\", color=\"orange\", marker='x')\n",
        "plt.title(\"Linear Regression: Actual vs Predicted\")\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"Number of Fatalities (best_est)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXc8zFlgfYpR"
      },
      "source": [
        "Random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "id": "ivobQkUbfYYt",
        "outputId": "4c7eea81-a313-4244-c1b0-e66b0f9e8c1a"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "# Metrics\n",
        "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
        "rmse_rf = np.sqrt(mse_rf)\n",
        "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
        "r2_rf = r2_score(y_test, y_pred_rf)\n",
        "mape_rf = np.mean(np.abs((y_test - y_pred_rf) / y_test.replace(0, np.nan))) * 100  # Avoid div by zero\n",
        "\n",
        "# Store in dictionary\n",
        "model_scores['Random Forest'] = {\n",
        "    \"MSE\": mse_rf,\n",
        "    \"RMSE\": rmse_rf,\n",
        "    \"MAE\": mae_rf,\n",
        "    \"R2 Score\": r2_rf,\n",
        "    \"MAPE\": mape_rf\n",
        "}\n",
        "\n",
        "print(\"Random Forest Metrics:\")\n",
        "for k, v in model_scores['Random Forest'].items():\n",
        "    print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(y_test.values, label=\"Actual\", color=\"blue\", marker='o')\n",
        "plt.plot(y_pred_rf, label=\"Predicted\", color=\"orange\", marker='x')\n",
        "plt.title(\"Random Forest: Actual vs Predicted\")\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"Number of Fatalities (best_est)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMSFkhawfoza"
      },
      "source": [
        "Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "id": "kLkX1Xgbfomx",
        "outputId": "a46c5ce5-9177-4f61-f064-bc90033f2c02"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "gb = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "gb.fit(X_train, y_train)\n",
        "\n",
        "y_pred_gb = gb.predict(X_test)\n",
        "\n",
        "# Metrics\n",
        "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
        "rmse_gb = np.sqrt(mse_gb)\n",
        "mae_gb = mean_absolute_error(y_test, y_pred_gb)\n",
        "r2_gb = r2_score(y_test, y_pred_gb)\n",
        "mape_gb = np.mean(np.abs((y_test - y_pred_gb) / y_test.replace(0, np.nan))) * 100  # Avoid division by zero\n",
        "\n",
        "# Store in dictionary\n",
        "model_scores['Gradient Boosting'] = {\n",
        "    \"MSE\": mse_gb,\n",
        "    \"RMSE\": rmse_gb,\n",
        "    \"MAE\": mae_gb,\n",
        "    \"R2 Score\": r2_gb,\n",
        "    \"MAPE\": mape_gb\n",
        "}\n",
        "\n",
        "print(\"Gradient Boosting Metrics:\")\n",
        "for k, v in model_scores['Gradient Boosting'].items():\n",
        "    print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(y_test.values, label=\"Actual\", color=\"blue\", marker='o')\n",
        "plt.plot(y_pred_gb, label=\"Predicted\", color=\"orange\", marker='x')\n",
        "plt.title(\"Gradient Boosting: Actual vs Predicted\")\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"Number of Fatalities (best_est)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X59Ym7Cjfhx6"
      },
      "source": [
        "xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "id": "BePUvYPGfhlT",
        "outputId": "db4622bf-ad63-4ba7-94e8-05b39fabac24"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "xgb = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "\n",
        "# Metrics\n",
        "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
        "rmse_xgb = np.sqrt(mse_xgb)\n",
        "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
        "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
        "mape_xgb = np.mean(np.abs((y_test - y_pred_xgb) / y_test.replace(0, np.nan))) * 100  # Avoid div by zero\n",
        "\n",
        "# Store in dictionary\n",
        "model_scores['XGBoost'] = {\n",
        "    \"MSE\": mse_xgb,\n",
        "    \"RMSE\": rmse_xgb,\n",
        "    \"MAE\": mae_xgb,\n",
        "    \"R2 Score\": r2_xgb,\n",
        "    \"MAPE\": mape_xgb\n",
        "}\n",
        "\n",
        "print(\"XGBoost Metrics:\")\n",
        "for k, v in model_scores['XGBoost'].items():\n",
        "    print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(y_test.values, label=\"Actual\", color=\"blue\", marker='o')\n",
        "plt.plot(y_pred_xgb, label=\"Predicted\", color=\"orange\", marker='x')\n",
        "plt.title(\"XGBoost: Actual vs Predicted\")\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"Number of Fatalities (best_est)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGolqakc1367"
      },
      "source": [
        "ARIMA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "id": "6ZVCkfnIWSiw",
        "outputId": "dcda7e1f-2a8a-4775-b7dd-390d1d4ca613"
      },
      "outputs": [],
      "source": [
        "ts_data = df1.groupby('year')['best_est'].sum()\n",
        "ts_data = ts_data.sort_index()\n",
        "\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Fit ARIMA (you may need to adjust the (p,d,q) order based on AIC/BIC later)\n",
        "model = ARIMA(ts_data, order=(1,1,1))\n",
        "arima_result = model.fit()\n",
        "\n",
        "# Predict for the next 5 years\n",
        "forecast_years = list(range(ts_data.index[-1] + 1, ts_data.index[-1] + 6))\n",
        "forecast_arima = arima_result.forecast(steps=5)\n",
        "\n",
        "# Combine with historical data\n",
        "ts_forecast = pd.Series(forecast_arima.values, index=forecast_years)\n",
        "\n",
        "# Plot actual vs forecasted\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(ts_data.index, ts_data.values, label='Actual', color='blue', marker='o')\n",
        "plt.plot(ts_forecast.index, ts_forecast.values, label='Forecast (ARIMA)', color='orange', marker='x')\n",
        "plt.title('ARIMA Model - Actual vs Forecasted Fatalities')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Total Fatalities')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Align actual and predicted for evaluation (use last 5 years of actuals)\n",
        "actual_arima = ts_data[-5:]\n",
        "predicted_arima = arima_result.predict(start=actual_arima.index[0], end=actual_arima.index[-1])\n",
        "\n",
        "# Metrics\n",
        "mse_arima = mean_squared_error(actual_arima, predicted_arima)\n",
        "rmse_arima = np.sqrt(mse_arima)\n",
        "mae_arima = mean_absolute_error(actual_arima, predicted_arima)\n",
        "r2_arima = r2_score(actual_arima, predicted_arima)\n",
        "mape_arima = np.mean(np.abs((actual_arima - predicted_arima) / np.where(actual_arima == 0, np.nan, actual_arima))) * 100\n",
        "\n",
        "# Store in model_scores1\n",
        "model_scores[\"ARIMA (Yearly)\"] = {\n",
        "    \"MSE\": mse_arima,\n",
        "    \"RMSE\": rmse_arima,\n",
        "    \"MAE\": mae_arima,\n",
        "    \"R2 Score\": r2_arima,\n",
        "    \"MAPE\": mape_arima\n",
        "}\n",
        "\n",
        "# Print\n",
        "print(\"\\nARIMA (Yearly) Metrics Stored in model_scores1:\")\n",
        "for k, v in model_scores[\"ARIMA (Yearly)\"].items():\n",
        "    print(f\"{k}: {v:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iV-VKEzzf4bX"
      },
      "source": [
        "SARIMA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9SAwtuxB3S2i",
        "outputId": "cab5094e-4ba3-46f2-bf74-ece678fdcec8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Step 1Ô∏è‚É£: Use conflict_copy dataset\n",
        "df = conflict_copy.copy()\n",
        "df['conflict_occurred'] = 1  # Each row represents a conflict\n",
        "conflicts_per_year = df.groupby('year')['conflict_occurred'].count()\n",
        "conflicts_per_year.index = conflicts_per_year.index.astype(int)\n",
        "\n",
        "# Step 2Ô∏è‚É£: Check for stationarity using ADF test\n",
        "def adf_test(timeseries):\n",
        "    result = adfuller(timeseries)\n",
        "    print(\"ADF Statistic:\", result[0])\n",
        "    print(\"p-value:\", result[1])\n",
        "    if result[1] <= 0.05:\n",
        "        print(\"‚úÖ The data is stationary.\")\n",
        "    else:\n",
        "        print(\"‚ùå The data is NOT stationary.\")\n",
        "\n",
        "adf_test(conflicts_per_year)\n",
        "\n",
        "# Step 3Ô∏è‚É£: Seasonal decomposition (for insight)\n",
        "decomposition = seasonal_decompose(conflicts_per_year, model=\"additive\", period=5)\n",
        "decomposition.plot()\n",
        "plt.show()\n",
        "\n",
        "# Step 4Ô∏è‚É£: Train-test split for time series (last 5 years as test)\n",
        "train = conflicts_per_year[:-5]\n",
        "test = conflicts_per_year[-5:]\n",
        "\n",
        "# Step 5Ô∏è‚É£: Fit SARIMA model (parameters are manually chosen)\n",
        "sarima_model = SARIMAX(train,\n",
        "                       order=(1, 1, 1),\n",
        "                       seasonal_order=(1, 1, 1, 5),\n",
        "                       enforce_stationarity=False,\n",
        "                       enforce_invertibility=False)\n",
        "sarima_fit = sarima_model.fit()\n",
        "print(sarima_fit.summary())\n",
        "\n",
        "# Step 6Ô∏è‚É£: Forecast for test period\n",
        "sarima_pred = sarima_fit.forecast(steps=len(test))\n",
        "\n",
        "# Step 7Ô∏è‚É£: Evaluate SARIMA model\n",
        "mse = mean_squared_error(test, sarima_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(test, sarima_pred)\n",
        "r2 = r2_score(test, sarima_pred)\n",
        "mape = np.mean(np.abs((test - sarima_pred) / test)) * 100\n",
        "\n",
        "# Step 8Ô∏è‚É£: Store and display metrics\n",
        "model_scores[\"SARIMA_1\"] = {\n",
        "    \"MSE\": mse,\n",
        "    \"RMSE\": rmse,\n",
        "    \"MAE\": mae,\n",
        "    \"R2 Score\": r2,\n",
        "    \"MAPE\": mape\n",
        "}\n",
        "\n",
        "print(\"\\nüìä SARIMA Evaluation Metrics:\")\n",
        "for metric, value in model_scores[\"SARIMA_1\"].items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "# Step 9Ô∏è‚É£: Plot actual vs predicted for test period\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(conflicts_per_year, label=\"Actual Conflicts\", marker=\"o\")\n",
        "plt.plot(test.index, sarima_pred, label=\"Predicted (Test)\", linestyle=\"--\", color=\"red\", marker=\"x\")\n",
        "plt.axvline(test.index[0], color=\"gray\", linestyle=\"--\", label=\"Train/Test Split\")\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Number of Conflicts\")\n",
        "plt.title(\"SARIMA Model: Actual vs Predicted Conflicts\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Step üîü (Optional): Forecast future 5 years\n",
        "future_forecast = sarima_fit.forecast(steps=5)\n",
        "future_years = np.arange(conflicts_per_year.index[-1] + 1, conflicts_per_year.index[-1] + 6)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(conflicts_per_year, label=\"Historical Conflicts\", marker=\"o\")\n",
        "plt.plot(future_years, future_forecast, label=\"Forecasted Conflicts\", linestyle=\"--\", color=\"green\", marker=\"s\")\n",
        "plt.axvline(conflicts_per_year.index[-1], color=\"gray\", linestyle=\"--\", label=\"Forecast Start\")\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Number of Conflicts\")\n",
        "plt.title(\"Forecast for Next 5 Years using SARIMA\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXNa66Bs9BZ7"
      },
      "source": [
        "LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FJ13HKlC9BET",
        "outputId": "4fa7505d-6829-4671-fb04-911af5c691db"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "df = conflict_copy.copy()\n",
        "\n",
        "# Aggregate data by year\n",
        "df['conflict_occurred'] = 1\n",
        "conflicts_per_year = df.groupby('year')['conflict_occurred'].count()\n",
        "\n",
        "# Convert index to integer years\n",
        "conflicts_per_year.index = conflicts_per_year.index.astype(int)\n",
        "\n",
        "# Normalize data (LSTMs work better with scaled data)\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "conflicts_scaled = scaler.fit_transform(conflicts_per_year.values.reshape(-1, 1))\n",
        "\n",
        "def create_sequences(data, time_steps=3):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - time_steps):\n",
        "        X.append(data[i:i+time_steps])\n",
        "        y.append(data[i+time_steps])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "time_steps = 3  # Use last 3 years to predict the next\n",
        "X, y = create_sequences(conflicts_scaled, time_steps)\n",
        "\n",
        "# Split into train (80%) and test (20%)\n",
        "train_size = int(len(X) * 0.8)\n",
        "X_train, X_test = X[:train_size], X[train_size:]\n",
        "y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "# Reshape input for LSTM (samples, timesteps, features)\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    LSTM(50, activation='relu', return_sequences=True, input_shape=(time_steps, 1)),\n",
        "    LSTM(50, activation='relu'),\n",
        "    Dense(1)  # Output layer\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=8, validation_data=(X_test, y_test), verbose=1)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Inverse transform predictions to original scale\n",
        "y_pred_inv = scaler.inverse_transform(y_pred)\n",
        "y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "\n",
        "# Plot Actual vs. Predicted\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(len(y_test_inv)), y_test_inv, label=\"Actual Conflicts\", marker=\"o\")\n",
        "plt.plot(range(len(y_pred_inv)), y_pred_inv, label=\"Predicted Conflicts\", marker=\"o\", linestyle=\"dashed\", color=\"red\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Number of Conflicts\")\n",
        "plt.title(\"LSTM Forecasting for Future Conflicts\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Get last 'time_steps' data points\n",
        "last_values = conflicts_scaled[-time_steps:].reshape(1, time_steps, 1)\n",
        "\n",
        "future_preds = []\n",
        "num_years = 5  # Forecast next 5 years\n",
        "\n",
        "for _ in range(num_years):\n",
        "    next_pred = model.predict(last_values)  # Predict next value\n",
        "    future_preds.append(next_pred[0, 0])  # Store prediction\n",
        "    last_values = np.append(last_values[:, 1:, :], next_pred.reshape(1, 1, 1), axis=1)  # ‚úÖ Fix dimension\n",
        "\n",
        "# Convert predictions back to original scale\n",
        "future_preds_inv = scaler.inverse_transform(np.array(future_preds).reshape(-1, 1))\n",
        "\n",
        "# Create future years\n",
        "future_years = np.arange(conflicts_per_year.index[-1] + 1, conflicts_per_year.index[-1] + 1 + num_years)\n",
        "\n",
        "# Plot Future Predictions\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(conflicts_per_year.index, conflicts_per_year, label=\"Actual Conflicts\", marker=\"o\")\n",
        "plt.plot(future_years, future_preds_inv, label=\"Forecasted Conflicts\", marker=\"o\", linestyle=\"dashed\", color=\"red\")\n",
        "plt.axvline(conflicts_per_year.index[-1], color=\"gray\", linestyle=\"--\", label=\"Forecast Start\")\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Number of Conflicts\")\n",
        "plt.title(\"LSTM Future Forecast\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Convert back to original scale\n",
        "y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "y_pred_inv = scaler.inverse_transform(y_pred)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100  # Avoid division by zero\n",
        "\n",
        "# Print Metrics\n",
        "print(f\"üîπ Mean Squared Error (MSE): {mse:.2f}\")\n",
        "print(f\"üîπ Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
        "print(f\"üîπ Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "print(f\"üîπ R¬≤ Score: {r2:.4f}\")\n",
        "\n",
        "model_scores[\"LSTM\"] = {\n",
        "    \"MSE\": mse,\n",
        "    \"RMSE\": rmse,\n",
        "    \"MAE\": mae,\n",
        "    \"R2 Score\": r2,\n",
        "    \"MAPE\": mape\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "id": "e7YtTZGmVO3b",
        "outputId": "aa254468-4d11-4a00-c2e6-cb16fbeaadd7"
      },
      "outputs": [],
      "source": [
        "# Group by year and sort\n",
        "ts_data = df1.groupby('year')['best_est'].sum()\n",
        "ts_data = ts_data.sort_index()\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Scale data (reshape to 2D first)\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(ts_data.values.reshape(-1, 1))\n",
        "\n",
        "# Prepare sequences (e.g., 5 years lookback)\n",
        "X, y = [], []\n",
        "for i in range(5, len(scaled_data)):\n",
        "    X.append(scaled_data[i-5:i])\n",
        "    y.append(scaled_data[i])\n",
        "\n",
        "X, y = np.array(X), np.array(y)\n",
        "\n",
        "# Reshape X for LSTM: (samples, time_steps, features)\n",
        "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "\n",
        "# Build LSTM model\n",
        "model_lstm = Sequential()\n",
        "model_lstm.add(LSTM(64, activation='relu', input_shape=(X.shape[1], 1)))\n",
        "model_lstm.add(Dense(1))\n",
        "model_lstm.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train\n",
        "model_lstm.fit(X, y, epochs=100, verbose=0)\n",
        "\n",
        "# Predict\n",
        "y_pred_lstm = model_lstm.predict(X)\n",
        "y_pred_lstm = scaler.inverse_transform(y_pred_lstm)\n",
        "actual_lstm = scaler.inverse_transform(y)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(actual_lstm, label='Actual', color='blue')\n",
        "plt.plot(y_pred_lstm, label='LSTM Predicted', color='orange', linestyle='--')\n",
        "plt.title(\"LSTM: Actual vs Predicted Fatalities\")\n",
        "plt.xlabel(\"Index (Time Steps)\")\n",
        "plt.ylabel(\"Fatalities\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Evaluation metrics\n",
        "mse_lstm = mean_squared_error(actual_lstm, y_pred_lstm)\n",
        "rmse_lstm = np.sqrt(mse_lstm)\n",
        "mae_lstm = mean_absolute_error(actual_lstm, y_pred_lstm)\n",
        "r2_lstm = r2_score(actual_lstm, y_pred_lstm)\n",
        "mape_lstm = np.mean(np.abs((actual_lstm - y_pred_lstm) / np.where(actual_lstm == 0, np.nan, actual_lstm))) * 100\n",
        "\n",
        "# Store in model_scores1\n",
        "model_scores[\"LSTM (Yearly)\"] = {\n",
        "    \"MSE\": mse_lstm,\n",
        "    \"RMSE\": rmse_lstm,\n",
        "    \"MAE\": mae_lstm,\n",
        "    \"R2 Score\": r2_lstm,\n",
        "    \"MAPE\": mape_lstm\n",
        "}\n",
        "\n",
        "# Print\n",
        "print(\"\\nLSTM (Yearly) Metrics Stored in model_scores1:\")\n",
        "for k, v in model_scores[\"LSTM (Yearly)\"].items():\n",
        "    print(f\"{k}: {v:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvUsFRIxWYKm"
      },
      "source": [
        "Prophet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mr2dzfrFWX_P",
        "outputId": "f0e47f4b-61af-4514-9d05-3a45c45c2f1f"
      },
      "outputs": [],
      "source": [
        "# Prepare monthly data\n",
        "df_time = df_clean[[\"date_start\", \"best\"]].copy()\n",
        "df_time = df_time.dropna()\n",
        "df_time[\"date_start\"] = pd.to_datetime(df_time[\"date_start\"])\n",
        "df_time = df_time.groupby(pd.Grouper(key=\"date_start\", freq=\"M\")).sum().reset_index()\n",
        "df_time.columns = [\"ds\", \"y\"]  # Prophet requires these column names\n",
        "\n",
        "# Check for missing time points\n",
        "df_time = df_time.set_index(\"ds\").asfreq(\"M\").reset_index()\n",
        "missing_months = df_time[\"y\"].isna().sum()\n",
        "print(f\"Missing months in time series: {missing_months}\")\n",
        "\n",
        "# Fill missing months with 0 if any\n",
        "df_time[\"y\"] = df_time[\"y\"].fillna(0)\n",
        "\n",
        "# Check for spikes (print summary)\n",
        "print(df_time[\"y\"].describe())\n",
        "\n",
        "# Cap outliers to the 99th percentile\n",
        "q99 = df_time[\"y\"].quantile(0.99)\n",
        "df_time[\"y\"] = np.where(df_time[\"y\"] > q99, q99, df_time[\"y\"])\n",
        "\n",
        "# Train/test split again after fixing\n",
        "train_size = int(len(df_time) * 0.8)\n",
        "train = df_time.iloc[:train_size]\n",
        "test = df_time.iloc[train_size:]\n",
        "\n",
        "# Re-train Prophet\n",
        "from prophet import Prophet\n",
        "model = Prophet()\n",
        "model.fit(train)\n",
        "\n",
        "# Predict\n",
        "future = model.make_future_dataframe(periods=len(test), freq='M')\n",
        "forecast = model.predict(future)\n",
        "\n",
        "# Evaluate\n",
        "predicted = forecast[['ds', 'yhat']].iloc[-len(test):].reset_index(drop=True)\n",
        "actual = test.reset_index(drop=True)\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "# Evaluate\n",
        "mae = mean_absolute_error(actual[\"y\"], predicted[\"yhat\"])\n",
        "mse = mean_squared_error(actual[\"y\"], predicted[\"yhat\"])\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(actual[\"y\"], predicted[\"yhat\"])\n",
        "mape = np.mean(np.abs((actual[\"y\"] - predicted[\"yhat\"]) / actual[\"y\"].replace(0, np.nan))) * 100  # Safe division\n",
        "\n",
        "# Store in dictionary\n",
        "model_scores[\"Prophet (Monthly)\"] = {\n",
        "    \"MSE\": mse,\n",
        "    \"RMSE\": rmse,\n",
        "    \"MAE\": mae,\n",
        "    \"R2 Score\": r2,\n",
        "    \"MAPE\": mape\n",
        "}\n",
        "\n",
        "print(\"\\nProphet (Monthly) Metrics Stored in model_scores1:\")\n",
        "for k, v in model_scores[\"Prophet (Monthly)\"].items():\n",
        "    print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(actual[\"ds\"], actual[\"y\"], label=\"Actual\", marker='o')\n",
        "plt.plot(predicted[\"ds\"], predicted[\"yhat\"], label=\"Predicted\", marker='x')\n",
        "plt.title(\"Prophet Forecast vs Actual Fatalities (After Cleaning)\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Fatalities\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixsNIACYl7pB"
      },
      "source": [
        "Storing model performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxOGqa8v_wo6",
        "outputId": "788d4a05-4e53-43e0-fd16-c25090daacb8"
      },
      "outputs": [],
      "source": [
        "model_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "RBqdZENfl7fT",
        "outputId": "f8e63514-6dfe-4791-d0de-d181640a3ae8"
      },
      "outputs": [],
      "source": [
        "df_scores = pd.DataFrame(model_scores).T\n",
        "print(\"\\nModel Performance Comparison:\\n\")\n",
        "df_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xJT09gGiQXo"
      },
      "source": [
        "#N-sampling method to compare the predictive analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3AOIOjCEAj34",
        "outputId": "962da6aa-1d6b-4ccd-ad61-b24a95315c65"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from math import pi\n",
        "\n",
        "# Your data in dictionary format\n",
        "model_results = model_scores\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame.from_dict(model_results, orient='index')\n",
        "df.reset_index(inplace=True)\n",
        "df.rename(columns={'index': 'Model'}, inplace=True)\n",
        "\n",
        "# Display the data\n",
        "print(\"Model Performance Metrics:\")\n",
        "print(df.to_string(index=False))\n",
        "\n",
        "# Visualization 1: Bar plot for each metric\n",
        "metrics = ['MSE', 'RMSE', 'MAE', 'R2 Score', 'MAPE']\n",
        "plt.figure(figsize=(15, 20))\n",
        "\n",
        "for i, metric in enumerate(metrics, 1):\n",
        "    plt.subplot(3, 2, i)\n",
        "    if metric == 'R2 Score':\n",
        "        # For R2, higher is better\n",
        "        sorted_df = df.sort_values(metric, ascending=False)\n",
        "        bars = plt.barh(sorted_df['Model'], sorted_df[metric], color='skyblue')\n",
        "        plt.title(f'{metric} (Higher is better)')\n",
        "        # Add value labels\n",
        "        for bar in bars:\n",
        "            width = bar.get_width()\n",
        "            plt.text(width, bar.get_y() + bar.get_height()/2, f'{width:.3f}',\n",
        "                    ha='left', va='center')\n",
        "    else:\n",
        "        # For error metrics, lower is better\n",
        "        sorted_df = df[df[metric].notna()].sort_values(metric)\n",
        "        bars = plt.barh(sorted_df['Model'], sorted_df[metric], color='lightcoral')\n",
        "        plt.title(f'{metric} (Lower is better)')\n",
        "        # Add value labels\n",
        "        for bar in bars:\n",
        "            width = bar.get_width()\n",
        "            plt.text(width, bar.get_y() + bar.get_height()/2, f'{width:.3f}',\n",
        "                    ha='left', va='center')\n",
        "\n",
        "    plt.xlabel(metric)\n",
        "    plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Model Performance Comparison', y=1.02, fontsize=16)\n",
        "plt.show()\n",
        "\n",
        "# Visualization 2: Radar chart for top models\n",
        "# Select top models based on R2 Score (excluding negative values)\n",
        "top_models = df[df['R2 Score'] > 0].sort_values('R2 Score', ascending=False).head(4)['Model'].values\n",
        "\n",
        "# Normalize metrics for radar chart (except R2 which is already normalized)\n",
        "df_normalized = df.copy()\n",
        "for metric in ['MSE', 'RMSE', 'MAE', 'MAPE']:\n",
        "    min_val = df[metric].min()\n",
        "    df_normalized[metric] = df[metric] / min_val\n",
        "\n",
        "df_radar = df_normalized[df_normalized['Model'].isin(top_models)]\n",
        "\n",
        "# Number of variables\n",
        "categories = ['MSE', 'RMSE', 'MAE', 'R2 Score', 'MAPE']\n",
        "N = len(categories)\n",
        "\n",
        "# Create radar chart\n",
        "plt.figure(figsize=(8, 8))\n",
        "ax = plt.subplot(111, polar=True)\n",
        "\n",
        "# Draw one axe per variable + add labels\n",
        "plt.xticks(np.linspace(0, 2*pi, N, endpoint=False), categories)\n",
        "ax.set_rlabel_position(0)\n",
        "plt.yticks([1, 2, 3, 4, 5], [\"1x\", \"2x\", \"3x\", \"4x\", \"5x\"], color=\"grey\", size=7)\n",
        "plt.ylim(0, 5)\n",
        "\n",
        "# Plot each model\n",
        "for idx, row in df_radar.iterrows():\n",
        "    values = row[categories].values.flatten().tolist()\n",
        "    values += values[:1]  # Complete the loop\n",
        "    angles = np.linspace(0, 2*pi, N, endpoint=False).tolist()\n",
        "    angles += angles[:1]\n",
        "\n",
        "    ax.plot(angles, values, linewidth=2, linestyle='solid', label=row['Model'])\n",
        "    ax.fill(angles, values, alpha=0.1)\n",
        "\n",
        "plt.title('Top Models Comparison (Normalized Metrics)', size=16, y=1.1)\n",
        "plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
        "plt.show()\n",
        "\n",
        "# Determine the best model based on multiple criteria\n",
        "# Rank each model for each metric and sum the ranks\n",
        "# For error metrics (MSE, RMSE, MAE, MAPE), lower is better\n",
        "# For R2, higher is better\n",
        "\n",
        "df_rank = df.copy()\n",
        "\n",
        "# Rank models for each metric\n",
        "for metric in ['MSE', 'RMSE', 'MAE', 'MAPE']:\n",
        "    df_rank[metric+'_rank'] = df_rank[metric].rank(ascending=True)\n",
        "\n",
        "df_rank['R2_rank'] = df_rank['R2 Score'].rank(ascending=False)\n",
        "\n",
        "# Calculate total rank (sum of individual ranks)\n",
        "df_rank['Total_rank'] = (df_rank['MSE_rank'] + df_rank['RMSE_rank'] +\n",
        "                         df_rank['MAE_rank'] + df_rank['R2_rank'] +\n",
        "                         df_rank['MAPE_rank'].fillna(len(df_rank)))  # Fill NA with worst rank\n",
        "\n",
        "# Sort by total rank\n",
        "df_rank = df_rank.sort_values('Total_rank')\n",
        "\n",
        "print(\"\\nModel Rankings (Lower total rank is better):\")\n",
        "print(df_rank[['Model', 'Total_rank']].to_string(index=False))\n",
        "\n",
        "# Best model\n",
        "best_model = df_rank.iloc[0]['Model']\n",
        "print(f\"\\nBest Model Based on Combined Metrics: {best_model}\")\n",
        "\n",
        "# Show top 3 models\n",
        "print(\"\\nTop 3 Models:\")\n",
        "print(df_rank[['Model', 'Total_rank']].head(3).to_string(index=False))\n",
        "\n",
        "# Additional insights\n",
        "print(\"\\nAdditional Insights:\")\n",
        "print(\"- XGBoost and Gradient Boosting show excellent performance with R2 > 0.99\")\n",
        "print(\"- Tree-based models (Random Forest, XGBoost, Gradient Boosting) dominate the top positions\")\n",
        "print(\"- Time series models (ARIMA, SARIMA, Prophet) perform poorly on this dataset\")\n",
        "print(\"- LSTM has low error metrics but negative R2, suggesting potential issues with the model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "YUl8nPGfe04W",
        "outputId": "673838aa-0dbd-47a4-e9d9-b992d292ca5a"
      },
      "outputs": [],
      "source": [
        "print(\"\\nModel Rankings (Lower total rank is better):\")\n",
        "styled_df = df_rank[['Model', 'Total_rank']].style.hide()\n",
        "styled_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "4pjNijkJfH1k",
        "outputId": "762e221b-a225-4aa2-9f8d-ea1561cf99c6"
      },
      "outputs": [],
      "source": [
        "print(\"\\nTop 3 Models:\")\n",
        "styled_df = df_rank[['Model', 'Total_rank']].head(3).style.hide()\n",
        "styled_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e78FSJ7LG4Jc"
      },
      "source": [
        "#5. Prescriptive Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGF77NPGXiGE"
      },
      "source": [
        "Adding Socio_economic factors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehxZBvTkXhos"
      },
      "outputs": [],
      "source": [
        "socio_df = pd.read_csv(\"https://raw.githubusercontent.com/bhadri-Raj-T/eda_project/refs/heads/main/socio_economic_factors.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "XwIeQdvBX9kQ",
        "outputId": "4fc18ddd-6b39-4fa2-e44c-162c5676f328"
      },
      "outputs": [],
      "source": [
        "# Keep only the indicator name and year columns\n",
        "years = [col for col in socio_df.columns if col.startswith(\"19\") or col.startswith(\"20\")]\n",
        "socio_df_clean = socio_df[['Series Name'] + years].copy()\n",
        "\n",
        "# Melt the dataset to long format: one row per indicator per year\n",
        "socio_long = socio_df_clean.melt(id_vars='Series Name', var_name='year', value_name='value')\n",
        "\n",
        "# Extract just the 4-digit year from strings like \"1990 [YR1990]\"\n",
        "socio_long['year'] = socio_long['year'].str.extract(r'(\\d{4})').astype(int)\n",
        "\n",
        "# Remove '..' placeholders and convert to numeric\n",
        "socio_long = socio_long[~socio_long['value'].isin(['..'])]\n",
        "socio_long['value'] = pd.to_numeric(socio_long['value'], errors='coerce')\n",
        "\n",
        "# Pivot the table to get one row per year, with each indicator as a column\n",
        "socio_wide = socio_long.pivot(index='year', columns='Series Name', values='value').reset_index()\n",
        "\n",
        "# Preview the reshaped data\n",
        "socio_wide.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8zhuWHOYEIu",
        "outputId": "c0b18f3a-ddfc-487a-95fc-ee6b4c45c6fe"
      },
      "outputs": [],
      "source": [
        "socio_wide.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "vqikKDmnYGu7",
        "outputId": "a683c99e-9e2a-48b4-a7f9-ec1ac64d4af6"
      },
      "outputs": [],
      "source": [
        "# Copy the original to preserve it\n",
        "socio_cleaned = socio_wide.copy()\n",
        "\n",
        "# Drop columns with more than 50% missing values\n",
        "threshold = 0.5  # 50%\n",
        "min_count = int(threshold * len(socio_cleaned))\n",
        "socio_cleaned = socio_cleaned.dropna(axis=1, thresh=min_count)\n",
        "\n",
        "# For remaining columns, apply interpolation or fill with mean\n",
        "for col in socio_cleaned.columns:\n",
        "    if socio_cleaned[col].isnull().sum() > 0:\n",
        "        if socio_cleaned[col].dtype in ['float64', 'int64']:\n",
        "            # Use linear interpolation for time series\n",
        "            socio_cleaned[col] = socio_cleaned[col].interpolate(method='linear', limit_direction='both')\n",
        "            # Fill remaining NaNs (if any) with column mean\n",
        "            socio_cleaned[col] = socio_cleaned[col].fillna(socio_cleaned[col].mean())\n",
        "\n",
        "# Confirm missing values are handled\n",
        "print(socio_cleaned.isnull().sum())\n",
        "socio_cleaned.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXd5JYW_YKPF",
        "outputId": "aca62558-cd72-4bd6-bf2c-c84e89607802"
      },
      "outputs": [],
      "source": [
        "socio_cleaned.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TLf6ZlSYM3i",
        "outputId": "d779c82b-d8c7-4e77-edd1-bce0d2d8d048"
      },
      "outputs": [],
      "source": [
        "df1.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "woRs2u7jYl5w",
        "outputId": "ae758807-a34d-49e0-cf27-74e4e60fb1b2"
      },
      "outputs": [],
      "source": [
        "# Make sure 'df1' (your conflict dataset) is ready\n",
        "# Group by year to get total fatalities\n",
        "fatalities_per_year = df1.groupby('year')['best_est'].sum().reset_index()\n",
        "\n",
        "# Merge with socio-economic data on 'year'\n",
        "combined_df1 = pd.merge(socio_cleaned, fatalities_per_year, on='year', how='inner')\n",
        "\n",
        "# Rename fatalities column for clarity\n",
        "combined_df1.rename(columns={'best_est': 'fatalities'}, inplace=True)\n",
        "\n",
        "# Preview merged dataset\n",
        "combined_df1.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdn5CocXYp0H",
        "outputId": "a5347320-8d68-4d66-a7ce-40343ad00301"
      },
      "outputs": [],
      "source": [
        "# Compute correlation matrix\n",
        "correlation_matrix = combined_df1.corr(numeric_only=True)\n",
        "\n",
        "# Show top correlations with fatalities\n",
        "correlation_with_fatalities = correlation_matrix['fatalities'].sort_values(ascending=False)\n",
        "print(\"Correlations with Conflict Fatalities:\\n\")\n",
        "print(correlation_with_fatalities)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801
        },
        "id": "ajbY8PxBYs88",
        "outputId": "4d192711-be8f-4dd9-ee42-96ff7a137de6"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set plot size\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Create the heatmap\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', square=True)\n",
        "plt.title(\"Correlation Between Socio-Economic Indicators and Conflict Fatalities\", fontsize=10)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "krF4nRsHZDkh",
        "outputId": "a4194d9a-193d-43b8-efe3-f4043a885ea7"
      },
      "outputs": [],
      "source": [
        "# Example: GDP growth vs Fatalities\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.scatterplot(data=combined_df1, x='GDP growth (annual %)', y='fatalities')\n",
        "plt.title(\"GDP Growth vs Conflict Fatalities\")\n",
        "plt.xlabel(\"GDP Growth (%)\")\n",
        "plt.ylabel(\"Total Fatalities\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.scatterplot(data=combined_df1, x='Vulnerable employment, total (% of total employment) (modeled ILO estimate)', y='fatalities')\n",
        "plt.title(\"Vulnerable employment vs Conflict Fatalities\")\n",
        "plt.xlabel(\"Vulnerable employment, total (% of total employment)\")\n",
        "plt.ylabel(\"Total Fatalities\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.scatterplot(data=combined_df1, x='School enrollment, secondary (% gross)', y='fatalities')\n",
        "plt.title(\"School enrollment vs Conflict Fatalities\")\n",
        "plt.xlabel(\"School enrollment, secondary (% gross)\")\n",
        "plt.ylabel(\"Total Fatalities\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.scatterplot(data=combined_df1, x='Children out of school (% of primary school age)', y='fatalities')\n",
        "plt.title(\"Children out of school  vs Conflict Fatalities\")\n",
        "plt.xlabel(\"Children out of school (% of primary school age)\")\n",
        "plt.ylabel(\"Total Fatalities\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.scatterplot(data=combined_df1, x='Primary education, pupils', y='fatalities')\n",
        "plt.title(\"Primary education, pupils  vs Conflict Fatalities\")\n",
        "plt.xlabel(\"Primary education, pupils\")\n",
        "plt.ylabel(\"Total Fatalities\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31bq7SKSZTeR"
      },
      "source": [
        "Socio_Economin_Factors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ATX5coBOZTQT",
        "outputId": "e25b3593-e69f-4ddb-e5c6-14944bbe5310"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "sef2_df1 = pd.read_csv(\"https://raw.githubusercontent.com/bhadri-Raj-T/eda_project/refs/heads/main/sef2.csv\")\n",
        "\n",
        "# Step 1: Keep only 'Series Name' and year columns\n",
        "year_cols = [col for col in sef2_df1.columns if col.startswith(\"19\") or col.startswith(\"20\")]\n",
        "sef2_clean = sef2_df1[['Series Name'] + year_cols].copy()\n",
        "\n",
        "# Step 2: Melt the dataset to long format\n",
        "sef2_long = sef2_clean.melt(id_vars='Series Name', var_name='year', value_name='value')\n",
        "\n",
        "# Step 3: Clean year column and convert to numeric\n",
        "sef2_long['year'] = sef2_long['year'].str.extract(r'(\\d{4})').astype(int)\n",
        "\n",
        "# Step 4: Remove placeholders like '..' and convert to float\n",
        "sef2_long = sef2_long[~sef2_long['value'].isin(['..'])]\n",
        "sef2_long['value'] = pd.to_numeric(sef2_long['value'], errors='coerce')\n",
        "\n",
        "# Step 5: Pivot to wide format (one row per year)\n",
        "sef2_wide = sef2_long.pivot(index='year', columns='Series Name', values='value').reset_index()\n",
        "\n",
        "# Show initial structure\n",
        "print(sef2_wide.info())\n",
        "\n",
        "# Step 6: Drop columns with more than 50% missing data\n",
        "threshold = 0.5  # 50% threshold\n",
        "min_non_na = int(threshold * len(sef2_wide))\n",
        "sef2_wide = sef2_wide.dropna(thresh=min_non_na, axis=1)\n",
        "\n",
        "# Step 7: Interpolate remaining missing values, fallback to mean\n",
        "for col in sef2_wide.columns:\n",
        "    if col != 'year' and sef2_wide[col].isnull().sum() > 0:\n",
        "        # Interpolate over years\n",
        "        sef2_wide[col] = sef2_wide[col].interpolate(method='linear', limit_direction='both')\n",
        "        # Fill any remaining NaNs with column mean\n",
        "        sef2_wide[col] = sef2_wide[col].fillna(sef2_wide[col].mean())\n",
        "\n",
        "# Step 8: Confirm cleanup\n",
        "print(\"Missing values after cleaning:\")\n",
        "print(sef2_wide.isnull().sum())\n",
        "sef2_wide.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6wEbes5cKjQ"
      },
      "source": [
        "fatalities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "tAd_aAXmZkAb",
        "outputId": "8e4f9361-6e9b-4a8d-a865-9a7063ce4f13"
      },
      "outputs": [],
      "source": [
        "# Step 1: Aggregate fatalities per year from conflict dataset\n",
        "fatalities_by_year = df1.groupby('year')['best_est'].sum().reset_index()\n",
        "fatalities_by_year.rename(columns={'best_est': 'fatalities'}, inplace=True)\n",
        "\n",
        "# Step 2: Merge with socio-economic data on 'year'\n",
        "merged_sef2 = pd.merge(sef2_wide, fatalities_by_year, on='year', how='inner')\n",
        "\n",
        "# Preview merged dataset\n",
        "merged_sef2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQo8lmq8ZtLW",
        "outputId": "288afc92-dca1-4cc1-9050-4670968362b9"
      },
      "outputs": [],
      "source": [
        "# Compute Spearman correlation matrix\n",
        "spearman_corr = merged_sef2.corr(method='spearman')\n",
        "\n",
        "# Show top correlations with fatalities\n",
        "print(spearman_corr['fatalities'].sort_values(ascending=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xlYnJAkkZwAN",
        "outputId": "b216073e-9ecf-43ae-fc81-92350ed51f98"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(14, 10))\n",
        "sns.heatmap(spearman_corr, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "plt.title(\"Spearman Correlation Heatmap: Socio-Economic Indicators vs Fatalities\")\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGbya6RaOelB"
      },
      "source": [
        "Linear programming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDd9JodJOebm",
        "outputId": "d518b52d-2d2e-4bd9-e5e7-43dcb0b317eb"
      },
      "outputs": [],
      "source": [
        "# Check for missing or zero values\n",
        "print(conflict_copy[['deaths_a', 'deaths_b', 'event_clarity', 'number_of_sources']].describe())\n",
        "\n",
        "# Drop rows with missing or zero values\n",
        "conflict_copy = conflict_copy.dropna(subset=['deaths_a', 'deaths_b', 'event_clarity', 'number_of_sources'])\n",
        "conflict_copy = conflict_copy[(conflict_copy['deaths_a'] > 0) & (conflict_copy['deaths_b'] > 0)]\n",
        "conflict_copy['event_clarity']=conflict_copy['event_clarity'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "IbEo4JCjOkRl",
        "outputId": "564a33e2-1075-4a11-a965-fd42c697c049"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pulp import LpMinimize, LpProblem, LpVariable, lpSum\n",
        "\n",
        "# Example: Ensure your DataFrame 'conflict_copy' is loaded beforehand\n",
        "# For example: conflict_copy = pd.read_csv(\"conflict_data.csv\")\n",
        "\n",
        "# Clean the data: Drop rows with NaN in required columns\n",
        "conflict_copy = conflict_copy.dropna(subset=['deaths_a', 'deaths_b', 'event_clarity', 'number_of_sources'])\n",
        "\n",
        "# Convert necessary columns to numeric (handle categorical issues)\n",
        "conflict_copy[\"deaths_a\"] = pd.to_numeric(conflict_copy[\"deaths_a\"], errors='coerce')\n",
        "conflict_copy[\"deaths_b\"] = pd.to_numeric(conflict_copy[\"deaths_b\"], errors='coerce')\n",
        "conflict_copy[\"event_clarity\"] = pd.to_numeric(conflict_copy[\"event_clarity\"], errors='coerce')\n",
        "conflict_copy[\"number_of_sources\"] = pd.to_numeric(conflict_copy[\"number_of_sources\"], errors='coerce')\n",
        "\n",
        "# Filter only positive death counts\n",
        "conflict_copy = conflict_copy[(conflict_copy['deaths_a'] > 0) & (conflict_copy['deaths_b'] > 0)]\n",
        "\n",
        "# Define the LP problem\n",
        "model = LpProblem(name=\"conflict_resource_optimization\", sense=LpMinimize)\n",
        "\n",
        "# Decision variables: Allocation of resources to each conflict zone\n",
        "zones = conflict_copy.index\n",
        "allocation = {z: LpVariable(name=f\"alloc_{z}\", lowBound=0) for z in zones}\n",
        "\n",
        "# Objective function: Minimize total deaths\n",
        "model += lpSum((conflict_copy.loc[z, \"deaths_a\"] + conflict_copy.loc[z, \"deaths_b\"]) * allocation[z] for z in zones), \"Minimize_Deaths\"\n",
        "\n",
        "# Constraint: Total resources cannot exceed 2x the sum of clarity and sources\n",
        "total_resources = 2 * (conflict_copy[\"event_clarity\"].sum() + conflict_copy[\"number_of_sources\"].sum())\n",
        "model += lpSum(allocation[z] for z in zones) <= total_resources, \"Total_Resource_Limit\"\n",
        "\n",
        "# Constraint: Minimum allocation for each zone\n",
        "for z in zones:\n",
        "    min_alloc = 0.1 * (conflict_copy.loc[z, \"deaths_a\"] + conflict_copy.loc[z, \"deaths_b\"])\n",
        "    model += allocation[z] >= min_alloc, f\"Min_Allocation_{z}\"\n",
        "\n",
        "# Solve the model\n",
        "model.solve()\n",
        "\n",
        "# Print results\n",
        "print(\"Optimal Resource Allocation:\")\n",
        "for z in zones:\n",
        "    print(f\"Conflict Zone {z}: {allocation[z].varValue:.2f}\")\n",
        "\n",
        "print(f\"\\nTotal Minimized Deaths: {model.objective.value():.2f}\")\n",
        "\n",
        "# Extract and plot optimal allocations\n",
        "optimal_allocations = [allocation[z].varValue for z in zones]\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(zones.astype(str), optimal_allocations, color='green')\n",
        "plt.xlabel(\"Conflict Zone\")\n",
        "plt.ylabel(\"Optimal Resource Allocation\")\n",
        "plt.title(\"Optimal Resource Allocation Across Conflict Zones\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUZOdbRnO-kJ"
      },
      "source": [
        "Optimization of resourses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-bqtaDCO-bo",
        "outputId": "45c26a86-658a-4f98-d409-3d69b5e4708c"
      },
      "outputs": [],
      "source": [
        "from scipy.optimize import minimize\n",
        "\n",
        "# Ensure data is clean\n",
        "conflict_copy = conflict_copy.dropna(subset=['deaths_a', 'deaths_b', 'event_clarity', 'number_of_sources'])\n",
        "conflict_copy = conflict_copy[(conflict_copy['deaths_a'] > 0) & (conflict_copy['deaths_b'] > 0)]\n",
        "\n",
        "# Define the objective function\n",
        "def objective(x):\n",
        "    deaths_a = conflict_copy['deaths_a'].values\n",
        "    deaths_b = conflict_copy['deaths_b'].values\n",
        "    # Maximize reduction in deaths (negative sign for maximization)\n",
        "    return -np.sum((deaths_a + deaths_b) * x)\n",
        "\n",
        "# Define constraints\n",
        "def resource_constraint(x):\n",
        "    total_resources = 2 * (conflict_copy[\"event_clarity\"].sum() + conflict_copy[\"number_of_sources\"].sum())  # Increased resources\n",
        "    return total_resources - np.sum(x)\n",
        "\n",
        "def min_allocation_constraint(x):\n",
        "    # Ensure minimum allocation of 0.1 * (deaths_a + deaths_b) for each zone\n",
        "    min_allocation = 0.1 * (conflict_copy['deaths_a'].values + conflict_copy['deaths_b'].values)\n",
        "    return x - min_allocation\n",
        "\n",
        "# Initial guess (start with small allocations)\n",
        "x0 = np.ones(len(conflict_copy)) * 0.1\n",
        "\n",
        "# Bounds (allocation cannot be negative)\n",
        "bounds = [(0, None) for _ in range(len(conflict_copy))]\n",
        "\n",
        "# Constraints\n",
        "constraints = [\n",
        "    {'type': 'ineq', 'fun': resource_constraint},  # Total resources constraint\n",
        "    {'type': 'ineq', 'fun': min_allocation_constraint}  # Minimum allocation constraint\n",
        "]\n",
        "\n",
        "# Solve the optimization problem\n",
        "result = minimize(objective, x0, bounds=bounds, constraints=constraints)\n",
        "\n",
        "# Print results\n",
        "print(\"Optimal Resource Allocation:\", result.x)\n",
        "print(\"Total Reduction in Deaths:\", -result.fun)  # Negative sign to convert back to positive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VthdB_9bO37q"
      },
      "source": [
        "DOwhy anaylsis\n",
        "Identify the causal impact of different factors on conflict intensity (measured via deaths).\n",
        "Recommend prescriptive actions to reduce conflict intensity.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjWvN2nRO3qt",
        "outputId": "3e063766-07ad-4486-e86c-1e4821401074"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from dowhy import CausalModel\n",
        "\n",
        "# Load dataset (assuming it's already loaded as df)\n",
        "# df = pd.read_csv(\"conflict_data.csv\") # Uncomment if loading from file\n",
        "\n",
        "# Define treatment, outcome, and confounders\n",
        "treatment = \"type_of_violence\"\n",
        "outcome = \"best\"\n",
        "confounders = [\"region\", \"country\", \"side_a\", \"side_b\", \"latitude\", \"longitude\"]\n",
        "\n",
        "# Build the Causal Model\n",
        "model = CausalModel(\n",
        "    data=conflict_copy,\n",
        "    treatment=treatment,\n",
        "    outcome=outcome,\n",
        "    common_causes=confounders\n",
        ")\n",
        "\n",
        "# Visualize the Causal Graph (DAG)\n",
        "plt.figure(figsize=(10,6))\n",
        "model.view_model(layout=\"dot\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rK0skC7tSDzT"
      },
      "source": [
        "Deep Q-Learning (DQN) ‚Üí Stable-Baselines3, TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSlI2JCHTMt0"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3 import DQN\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "\n",
        "# Create a vectorized environment (Colab-friendly)\n",
        "env = make_vec_env(\"CartPole-v1\", n_envs=1)\n",
        "\n",
        "# Train DQN Model\n",
        "model = DQN(\"MlpPolicy\", env, verbose=1)\n",
        "model.learn(total_timesteps=10000)\n",
        "\n",
        "# Save & Load the Model\n",
        "model.save(\"dqn_cartpole\")\n",
        "del model  # Remove from memory\n",
        "model = DQN.load(\"dqn_cartpole\")\n",
        "\n",
        "# Test the trained model\n",
        "obs = env.reset()\n",
        "for _ in range(1000):\n",
        "    action, _ = model.predict(obs)\n",
        "    obs, rewards, dones, info = env.step(action)\n",
        "    env.render()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqJhXAjKSDiQ",
        "outputId": "9f6d0401-c81b-4f0b-c4ea-6abf55316721"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "from gym import spaces\n",
        "from stable_baselines3 import DQN\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Custom Conflict Management Environment\n",
        "class ConflictEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        super(ConflictEnv, self).__init__()\n",
        "\n",
        "        # Action Space: 0 = No Action, 1 = Deploy Resources, 2 = Increase Surveillance\n",
        "        self.action_space = spaces.Discrete(3)\n",
        "\n",
        "        # Observation Space: Conflicts, Deaths, Event Clarity, Sources\n",
        "        self.observation_space = spaces.Box(low=0, high=100, shape=(4,), dtype=np.float32)\n",
        "\n",
        "        self.state = None\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = np.array([50, 10, 5, 3], dtype=np.float32)  # Starting state\n",
        "        return self.state\n",
        "\n",
        "    def step(self, action):\n",
        "        conflicts, deaths, event_clarity, sources = self.state\n",
        "\n",
        "        # Apply Actions\n",
        "        if action == 1:  # Deploy Resources\n",
        "            conflicts = max(0, conflicts - 5)\n",
        "            deaths = max(0, deaths - 2)\n",
        "        elif action == 2:  # Increase Surveillance\n",
        "            event_clarity = min(100, event_clarity + 2)\n",
        "            sources = min(100, sources + 1)\n",
        "\n",
        "        # Reward: lower conflicts & deaths + better clarity/sources\n",
        "        reward = (100 - conflicts) + (50 - deaths) + (event_clarity * 2) + (sources * 3)\n",
        "\n",
        "        self.state = np.array([conflicts, deaths, event_clarity, sources], dtype=np.float32)\n",
        "        done = conflicts <= 0\n",
        "\n",
        "        return self.state, reward, done, {}\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        print(f\"State: Conflicts={self.state[0]}, Deaths={self.state[1]}, Clarity={self.state[2]}, Sources={self.state[3]}\")\n",
        "\n",
        "# Create Environment\n",
        "env = ConflictEnv()\n",
        "\n",
        "# Train DQN Model\n",
        "model = DQN(\"MlpPolicy\", env, verbose=1)\n",
        "model.learn(total_timesteps=10000)\n",
        "\n",
        "# Test the Trained Model\n",
        "obs = env.reset()\n",
        "states, rewards_log = [], []\n",
        "\n",
        "for step in range(20):\n",
        "    action, _ = model.predict(obs)\n",
        "    obs, reward, done, _ = env.step(action)\n",
        "    env.render()\n",
        "    states.append(obs.copy())\n",
        "    rewards_log.append(reward)\n",
        "    if done:\n",
        "        break\n",
        "\n",
        "# Visualization: Rewards over Steps\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(rewards_log, marker='o', color='darkgreen')\n",
        "plt.title(\"Reward Over Time Steps\")\n",
        "plt.xlabel(\"Step\")\n",
        "plt.ylabel(\"Reward\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR3ykWRzr6zM"
      },
      "source": [
        "Absolutely ‚Äî let‚Äôs break down your results and extract **data-driven insights** along with **actionable policy recommendations**.\n",
        "\n",
        "---\n",
        "\n",
        "# **Insights from Spearman and Pearson Correlations**\n",
        "\n",
        "## 1. **Strong Positive Correlation with Fatalities**\n",
        "###  *Battle-related deaths (r = 0.63, Spearman)*  \n",
        "This is expected ‚Äî UCDP's `best_est` and battle-related deaths should overlap. It confirms your target variable is consistent with battle metrics.\n",
        "\n",
        "**Use this as a validation point** in your methodology:  \n",
        "\"The strong correlation between `best_est` and battle-related deaths validates that our dataset reflects actual conflict intensity.\"\n",
        "\n",
        "---\n",
        "\n",
        "## 2. **Military & Defense-Related Indicators**\n",
        "###  *Arms Exports (r = 0.30, Spearman)*  \n",
        "###  *Military Expenditure (% of GDP) (r = 0.29, Spearman)*  \n",
        " Countries with higher military activity may face higher conflict fatalities, suggesting increased militarization could fuel conflict escalation ‚Äî especially if not paired with peacebuilding efforts.\n",
        "\n",
        "**Insight**:  \n",
        "*\"A rise in military spending and arms exports appears moderately linked with increased conflict fatalities. While defense may be essential, unchecked militarization could worsen internal tensions.\"*\n",
        "\n",
        "**Policy Recommendations**:\n",
        "- Implement transparency in defense budgeting.\n",
        "- Balance military expenditure with peacebuilding investments (e.g., conflict resolution education, local peace councils).\n",
        "- Promote arms trade regulation with conflict-sensitive policies.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. **Demographic Indicators**\n",
        "###  *Population Ages 0‚Äì14, Male (r = 0.17)*  \n",
        " A younger, male-heavy population is sometimes correlated with unrest if youth are unemployed or disenfranchised ‚Äî often referred to as the **\"youth bulge\" hypothesis**.\n",
        "\n",
        " **Insight**:  \n",
        "\"Regions with large young male populations may require targeted interventions, as youth marginalization can be a risk factor for conflict.\"\n",
        "\n",
        "**Policy Recommendations**:\n",
        "- Invest in youth education and vocational programs.\n",
        "- Promote inclusive youth political participation and representation.\n",
        "- Launch youth employment schemes in high-risk regions.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. **Negative Correlation with Fatalities (Risk Reducing Factors)**\n",
        "\n",
        "###  *Refugee Population by Country (-0.43, Spearman)*  \n",
        "India‚Äôs role as a host country might align with regional humanitarian stability or international cooperation. Lower fatalities where refugee policies are in place might be a signal of **international engagement**.\n",
        "\n",
        "**Insight**:  \n",
        "*\"Hosting refugees and participating in international humanitarian efforts may align with reduced conflict fatalities.\"*\n",
        "\n",
        "**Policy Recommendations**:\n",
        "- Strengthen refugee protection policies and align with UNHCR best practices.\n",
        "- Leverage international peacebuilding aid tied to refugee support programs.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. **Education & Employment (from Pearson correlations)**\n",
        "\n",
        "###  *Vulnerable Employment (r = 0.34)*  \n",
        "###  *Low School Enrollment (r = -0.12 to -0.18)*  \n",
        "High vulnerable employment (e.g., informal jobs with no security) and low school enrollment are lightly correlated with fatalities.\n",
        "\n",
        " **Insight**:  \n",
        "*\"Socio-economic instability, particularly lack of secure employment and low education access, correlates with greater conflict fatality rates.\"*\n",
        "\n",
        " **Policy Recommendations**:\n",
        "- Expand formal job opportunities in rural/conflict-prone areas.\n",
        "- Promote universal basic education and reduce drop-out rates.\n",
        "- Support vocational training and skill development in underserved districts.\n",
        "\n",
        "---\n",
        "\n",
        "# Summary: Data-Driven Conflict Reduction Policy Strategy\n",
        "\n",
        "| Focus Area         | Risk Factor                | Recommendation                                                                 |\n",
        "|--------------------|----------------------------|--------------------------------------------------------------------------------|\n",
        "| Military Spending  | High arms exports/expenditure | Increase transparency & balance with peace initiatives                          |\n",
        "| Youth Demographics | Large male youth population | Target youth for jobs, education, and political inclusion                       |\n",
        "| Education Access   | Low enrollment rates        | Universalize primary and secondary education                                   |\n",
        "| Job Security       | Vulnerable employment       | Create formal job schemes in rural/conflict zones                              |\n",
        "| International Role | Refugee population          | Strengthen refugee protection and use it as leverage for peacebuilding funding |\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3TRdm5oYnr-"
      },
      "source": [
        "#Pre-profiling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "lzvuR3sYYsH8",
        "outputId": "3dd6fbe2-b18f-4ec5-b05e-0e272805ebe9"
      },
      "outputs": [],
      "source": [
        "import ydata_profiling as prf\n",
        "# Generate report\n",
        "profile =prf.ProfileReport(conflict_copy, title=\"Conflict Data Pre-Profiling Report\", explorative=True)\n",
        "# Save the report as HTML\n",
        "profile.to_file(\"conflict_data_profiling.html\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 822
        },
        "id": "1UB7_cTGakeC",
        "outputId": "ea807c47-ca01-423e-84e9-ebced16f86b0"
      },
      "outputs": [],
      "source": [
        "profile"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "tY8oBew_OUqg",
        "CzeYPEmJR0nN",
        "S6J59H67RDE-",
        "p42qFTsQlabN",
        "7xJT09gGiQXo",
        "e78FSJ7LG4Jc",
        "t3TRdm5oYnr-"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
